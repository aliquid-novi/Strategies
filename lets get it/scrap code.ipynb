{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e6ed69b-cb87-49ca-9d95-efa8406f56b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# T1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59faba4-f9f6-4618-aeef-49d8f7fd850a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Linear Regress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c74b81-cc19-4b48-ae59-8e3731d21c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebugMarkovChain(MarkovChain):\n",
    "    \n",
    "    def __init__(self, markov_chain_obj, states_dict):\n",
    "        # Assuming markov_chain_obj has a 'states' attribute and a 'transition_matrix' attribute\n",
    "        super().__init__(markov_chain_obj.states, states_dict)  # Call the parent class's __init__ method\n",
    "        self.transition_matrix = markov_chain_obj.transition_matrix  # Copy the transition matrix\n",
    "        self.classifier = DebugStateClassifier(states_dict)\n",
    "        self.states_dict = states_dict\n",
    "        \n",
    "    def current_state(self, pair, current_sample):\n",
    "        activation_model = self.states_dict[pair]['activation_model']\n",
    "        current_activations = activation_model.predict(current_sample)\n",
    "​\n",
    "        # Use DBSCAN to identify the state\n",
    "        db = self.states_dict[pair]['DB_scan']\n",
    "        closest_index, _ = pairwise_distances_argmin_min(current_activations, db.components_)\n",
    "        current_state = db.labels_[closest_index][0]\n",
    "​\n",
    "        return current_state\n",
    "        \n",
    "    def substate_create_new_probability_matrix(self, original_matrix):\n",
    "        new_prob_matrix = {}\n",
    "        for pair, transitions in original_matrix.items():\n",
    "            pair_prob_matrix = {}\n",
    "            for from_state, to_states in transitions.items():\n",
    "                # Remove this line to include all types of states\n",
    "                if isinstance(from_state, (int, np.int64)) or (isinstance(from_state, str)):  # Add this line to check the type of key\n",
    "                    total_transitions = sum(to_states.values())\n",
    "                    pair_prob_matrix[from_state] = {to_state: count / total_transitions for to_state, count in to_states.items()}\n",
    "            new_prob_matrix[pair] = pair_prob_matrix\n",
    "        return new_prob_matrix\n",
    "​\n",
    "    def substate_update_transition_matrix(self, original_matrix, pair, sub_states, meta_state, next_meta_state=None):\n",
    "        new_transitions = defaultdict(lambda: defaultdict(int))\n",
    "        sub_states = [int(s) for s in sub_states]\n",
    "        meta_state = int(meta_state)  # Ensure meta_state is a native Python integer\n",
    "​\n",
    "        if meta_state not in new_transitions:\n",
    "            new_transitions[meta_state] = defaultdict(int)\n",
    "            # print('metastate not in new_transitions. adding now.')\n",
    "        if f\"{meta_state}-{sub_states[0]}\" not in new_transitions[meta_state]:\n",
    "            # print('metastate not in new_transitions meta state. adding now')\n",
    "            new_transitions[meta_state][f\"{meta_state}-{sub_states[0]}\"] = 0\n",
    "            \n",
    "        new_transitions[meta_state][f\"{meta_state}-{sub_states[0]}\"] += 1\n",
    "        print(f'Added count of {new_transitions[meta_state]}')\n",
    "        \n",
    "        # Adding transitions between sub-states\n",
    "        for i in range(len(sub_states) - 1):\n",
    "            from_state = f\"{meta_state}-{sub_states[i]}\"\n",
    "            to_state = f\"{meta_state}-{sub_states[i + 1]}\"\n",
    "            new_transitions[from_state][to_state] += 1\n",
    "​\n",
    "        # Adding transitions from meta-state to the first sub-state in each sequence\n",
    "        new_transitions[meta_state][f\"{meta_state}-{sub_states[0]}\"] += 1\n",
    "​\n",
    "        # Adding transitions from the last sub-state in each sequence to the next meta-state if provided\n",
    "        if next_meta_state is not None:\n",
    "            new_transitions[f\"{meta_state}-{sub_states[-1]}\"][next_meta_state] += 1\n",
    "        else:\n",
    "            # If next meta-state is not provided, transition back to the same meta-state\n",
    "            new_transitions[f\"{meta_state}-{sub_states[-1]}\"][meta_state] += 1\n",
    "​\n",
    "        # Merge new transitions into the original matrix for the specific pair\n",
    "        if pair not in original_matrix:\n",
    "            original_matrix[pair] = {}\n",
    "​\n",
    "        # Merge new transitions into the original matrix for the specific pair\n",
    "        if pair not in original_matrix:\n",
    "            original_matrix[pair] = {}\n",
    "​\n",
    "        for from_state, to_states in new_transitions.items():\n",
    "            if from_state not in original_matrix[pair]:\n",
    "                # print(f\"Adding new from_state {from_state} to original_matrix\")\n",
    "                original_matrix[pair][from_state] = {}\n",
    "​\n",
    "            for to_state, count in to_states.items():\n",
    "                if to_state not in original_matrix[pair][from_state]:\n",
    "                    # print(f\"Adding new to_state {to_state} to original_matrix[{pair}][{from_state}]\")\n",
    "                    original_matrix[pair][from_state][to_state] = 0\n",
    "​\n",
    "                original_matrix[pair][from_state][to_state] += count\n",
    "                # print(f\"Updated count for original_matrix[{pair}][{from_state}][{to_state}] to {original_matrix[pair][from_state][to_state]}\")\n",
    "class DebugStateClassifier:\n",
    "    def __init__(self, states_dict):\n",
    "        self.states_dict = states_dict\n",
    "        # Initialize NearestNeighbors models for each pair\n",
    "        self.nn_models = {}\n",
    "        for pair, values in self.states_dict.items():\n",
    "            activations = values[\"activation_model\"].predict(values[\"data\"])  # Assuming \"data\" contains original features for each pair\n",
    "            self.nn_models[pair] = NearestNeighbors(n_neighbors=1).fit(activations)\n",
    "​\n",
    "    def classify_sample(self, sample, pair):\n",
    "        activation = self.states_dict[pair][\"activation_model\"].predict(sample)\n",
    "        distance, index = self.nn_models[pair].kneighbors(activation)\n",
    "        states = self.states_dict[pair][\"states\"]\n",
    "        state = states[index[0][0]]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc7d3c-eecb-46c8-86b8-2dd2a2e407e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the objective function to minimize (MSE)\n",
    "def objective(params):\n",
    "    predicted = np.dot(X_test, params)\n",
    "    mse = np.mean((predicted - y_test) ** 2)\n",
    "    return mse\n",
    "\n",
    "predictions = {} \n",
    "\n",
    "for pair, features_df in features_dict.items():\n",
    "    \n",
    "    # Prepare the data\n",
    "    X = features_df.values  # Feature values\n",
    "    y = coint_dict[pair].values[59:]  # All values as target\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a linear regression model as an example\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    # print(f\"Mean Squared Error for {pair}: {mse}\")\n",
    "    \n",
    "     # Initialize the parameters for optimization (e.g., as all ones)\n",
    "    initial_params = np.ones(X_test.shape[1])\n",
    "\n",
    "    # Use simulated annealing to optimize the parameters\n",
    "    result = opt.basinhopping(objective, initial_params, niter=100, stepsize=0.5)\n",
    "\n",
    "    # Get the optimized parameters\n",
    "    optimized_params = result.x\n",
    "\n",
    "    # Re-predict using the optimized parameters\n",
    "    y_pred_optimized = np.dot(X_test, optimized_params)\n",
    "\n",
    "    # Save the prediction\n",
    "    predictions[pair] = y_pred_optimized[0]\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred_optimized)\n",
    "    r_squared_optimized = r2_score(y_test, y_pred_optimized)\n",
    "    print(f\"Mean Squared Error for {pair}: {mse}\")\n",
    "    # print(f'R-squared (R^2) for {pair}: {r_squared_optimized}')\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff2577-d844-498c-be0d-229614ac3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Define the objective function to minimize (MSE)\n",
    "def objective(params):\n",
    "    predicted = np.dot(X_test, params)\n",
    "    mse = np.mean((predicted - y_test) ** 2)\n",
    "    return mse\n",
    "\n",
    "predictions_today = {} \n",
    "predictions_tomorrow = {} \n",
    "change_in_predictions = {}\n",
    "\n",
    "current_datetime = datetime.datetime.now()\n",
    "current_date_str = current_datetime.strftime('%Y-%m-%d %H:%M:%S %Z')\n",
    "\n",
    "def standard_linear_regress():\n",
    "    \n",
    "    print('Beginning Normal Standard Linear Regression')\n",
    "    print('')\n",
    "    for pair, features_df in features_dict.items():\n",
    "        # Prepare the data\n",
    "        X = features_df.values[:-2]  # Exclude last two values for today's and tomorrow's prediction\n",
    "        y = coint_dict[pair].values[59:-2]  # Similarly, exclude the last two values \n",
    "\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Train a linear regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict for today and tomorrow using the most recent features\n",
    "        prediction_today = model.predict([features_df.iloc[-2, :].values])[0]\n",
    "        prediction_tomorrow = model.predict([features_df.iloc[-1, :].values])[0]\n",
    "\n",
    "        predictions_today[pair] = prediction_today\n",
    "        predictions_tomorrow[pair] = prediction_tomorrow\n",
    "        change_in_predictions[pair] = prediction_today - model.predict([features_df.iloc[-3, :].values])[0]\n",
    "\n",
    "    print(f\"Time is {current_date_str}.\")\n",
    "    for pair in predictions_today.keys():\n",
    "        current_price = round(compute_spread(pair).iloc[-1], 5)\n",
    "        print(f\"For {pair}:\")\n",
    "        print(f\"Today's prediction: {predictions_today[pair]:.5f}. Current price: {current_price}\")\n",
    "        print(f\"Tomorrow's prediction: {predictions_tomorrow[pair]:.5f}\")\n",
    "        print(f\"Change in prediction compared to yesterday: {change_in_predictions[pair]:.5f}\")\n",
    "        print(\"-----\")\n",
    "\n",
    "standard_linear_regress()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cab5fe1-a614-4283-b3b7-1200565894fc",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9e397-255b-4c1a-b213-acff4d7321ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coint_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#TESTING\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair, data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcoint_dict\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning through \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.80\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'coint_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "for pair, data in coint_dict.items():\n",
    "    print(f\"Running through {pair}\")\n",
    "    split = int(len(data)*0.80)\n",
    "    train_set, test_set = data[:split], data[split:]\n",
    "    \n",
    "    model = ARIMA(train_set, order=(2, 1, 2))\n",
    "    model_fit_0 = model.fit()\n",
    "    \n",
    "    # Convert pandas series to list for rolling window forecast\n",
    "    past = train_set.tolist()\n",
    "\n",
    "    # Empty list for storing predictions\n",
    "    predictions = []\n",
    "\n",
    "    # Keeping only the first 50 data in the test dataset.\n",
    "    # You can run on the whole dataset, but it will take time to run.\n",
    "    test_set = test_set[:50]\n",
    "\n",
    "    # Perform rolling window forecast\n",
    "    for i in range(len(test_set)):\n",
    "        # Define ARIMA model\n",
    "        model = ARIMA(past, order=(2, 1, 2))\n",
    "        # Fit the model\n",
    "        model_fit = model.fit(start_params=model_fit_0.params)\n",
    "        # Make forecast\n",
    "        forecast_results = model_fit.forecast()\n",
    "        pred = forecast_results[0]\n",
    "        # Append prediction\n",
    "        predictions.append(pred)\n",
    "        # Add test value to train set\n",
    "        past.append(test_set[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6192a-750e-49ed-9322-822b3bdbae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR AND MA\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "for pair, data in coint_dict.items():\n",
    "    print(f\"Running through {pair}\")\n",
    "    split = int(len(data)*0.80)\n",
    "    train_set, test_set = data[:split], data[split:]\n",
    "\n",
    "    # Empty list to store aic/bic score\n",
    "    aic_p = []\n",
    "    bic_p = []\n",
    "\n",
    "    # p values\n",
    "    p = range(1, 6)  # [1,2,3,4,5]\n",
    "\n",
    "    # AIC/BIC score for different values of p\n",
    "    for i in p:\n",
    "        # Define the AR model\n",
    "        model = ARIMA(train_set, order=(i, 1, 0))  \n",
    "        # Fit the model\n",
    "        model_fit = model.fit()\n",
    "        # Get AIC score\n",
    "        aic_temp = model_fit.aic  \n",
    "        # Get BIC score\n",
    "        bic_temp = model_fit.bic\n",
    "        # Append AIC score\n",
    "        aic_p.append(aic_temp) \n",
    "        # Append BIC score\n",
    "        bic_p.append(bic_temp) \n",
    "\n",
    "    # Plot of AIC/BIC score for AR term\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(range(1, 6), aic_p, color='red')\n",
    "    plt.plot(range(1, 6), bic_p)\n",
    "    plt.title('Tuning AR term')\n",
    "    plt.xlabel('p (AR term)')\n",
    "    plt.ylabel('AIC/BIC score')\n",
    "    plt.legend(['AIC score', 'BIC score'])\n",
    "    plt.show() \n",
    "    \n",
    "for pair, data in coint_dict.items():\n",
    "    print(f\"Running through {pair}\")\n",
    "    split = int(len(data)*0.80)\n",
    "    train_set, test_set = data[:split], data[split:]\n",
    "\n",
    "    # Empty list to store AIC/BIC score\n",
    "    aic_q = []\n",
    "    bic_q = []\n",
    "\n",
    "    # q values\n",
    "    q = range(1, 6)\n",
    "\n",
    "    # AIC/BIC score for different values of q\n",
    "    for i in q:\n",
    "        model = ARIMA(train_set, order=(0, 1, i))\n",
    "        model_fit = model.fit()\n",
    "        aic_temp = model_fit.aic\n",
    "        bic_temp = model_fit.bic\n",
    "        aic_q.append(aic_temp)\n",
    "        bic_q.append(bic_temp)\n",
    "\n",
    "    # Plot of AIC/BIC score for MA term\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(range(1, 6), aic_q, color='red')\n",
    "    plt.plot(range(1, 6), bic_q)\n",
    "    plt.title('Tuning MA term')\n",
    "    plt.xlabel('q (MA term)')\n",
    "    plt.ylabel('AIC/BIC score')\n",
    "    plt.legend(['AIC score', 'BIC score'])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
