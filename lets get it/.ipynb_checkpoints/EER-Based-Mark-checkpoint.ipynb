{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "8e554905-3bf9-434b-8b11-e70a239e5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt5 \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller \n",
    "from datetime import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "mt5.initialize()\n",
    "# Replace following with your MT5 Account Login\n",
    "account=51434456 # \n",
    "password=\"9UpBvVzc\"\n",
    "server = 'ICMarkets-Demo'\n",
    "\n",
    "def get_rates(pair1, timeframe, x):\n",
    "    pair1 = pd.DataFrame(mt5.copy_rates_from_pos(pair1, timeframe, 0, x))\n",
    "    pair1['time'] = pd.to_datetime(pair1['time'], unit = 's')\n",
    "    return pair1[['time','open', 'high', 'low', 'close']].set_index('time')\n",
    "\n",
    "def forward_fill_non_zero(df, column_name):\n",
    "    last_non_zero = None\n",
    "    for idx in df.index:\n",
    "        value = df.loc[idx, column_name]\n",
    "        if value != 0:\n",
    "            last_non_zero = value\n",
    "        elif last_non_zero is not None:\n",
    "            df.at[idx, column_name] = last_non_zero\n",
    "    return df\n",
    "\n",
    "def calc_stats(df):\n",
    "\n",
    "    stats_df = pd.DataFrame()\n",
    "    stats_df['mean'] = df.mean()\n",
    "    stats_df['std'] = df.std()\n",
    "    # print('calculated')\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "f4be58db-a96f-4f52-b2a5-a7cdd9f7c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f205d57-36c5-4265-bc00-d6389b5182b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### profitlosscontrol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "8e9c938d-fdf1-41c2-a19d-cd4c0c5e3894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_date=datetime(2023,12, 16)\n",
    "to_date=datetime.now()\n",
    "order_hist = mt5.history_deals_get(from_date, to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "6ce4feaf-d449-4f85-9d47-33485ecf75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_dict = {}\n",
    "for pos in order_hist:\n",
    "    if pos.profit != 0.0:\n",
    "        hist_dict[pos.ticket] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "0e5f5ebd-e021-4e8f-aa16-13cfe51aed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lst = []\n",
    "\n",
    "for key, pos in hist_dict.items():\n",
    "    new_lst.append([pos.time, pos.swap, pos.commission, pos.profit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "c4a16670-8316-4f76-b26e-84ace6f84a64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for pos in new_lst:\n",
    "    unix_time = pos[0]\n",
    "    date_time = datetime.fromtimestamp(unix_time)\n",
    "    pos[0] = date_time.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "0e4cfda4-da32-46d7-a6c3-15fa6825a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "0a8eea76-58f5-4c50-b5fe-604a749da3c5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Swap</th>\n",
       "      <th>Commission</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-20 18:32:00</th>\n",
       "      <td>5.80</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-819.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-20 18:32:00</th>\n",
       "      <td>-16.49</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>461.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-20 18:32:01</th>\n",
       "      <td>-53.72</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>812.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-20 18:32:01</th>\n",
       "      <td>-1.65</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>658.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-20 18:32:02</th>\n",
       "      <td>38.89</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>1941.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-20 18:32:02</th>\n",
       "      <td>-6.16</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>915.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-20 18:32:03</th>\n",
       "      <td>-27.88</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-420.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22 15:12:18</th>\n",
       "      <td>-8.29</td>\n",
       "      <td>-5.71</td>\n",
       "      <td>693.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22 15:12:19</th>\n",
       "      <td>-3.30</td>\n",
       "      <td>-10.89</td>\n",
       "      <td>-2455.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22 15:12:20</th>\n",
       "      <td>-2.71</td>\n",
       "      <td>-6.27</td>\n",
       "      <td>-648.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22 15:12:21</th>\n",
       "      <td>-3.60</td>\n",
       "      <td>-4.31</td>\n",
       "      <td>436.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22 15:12:21</th>\n",
       "      <td>-17.82</td>\n",
       "      <td>-6.79</td>\n",
       "      <td>397.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22 15:12:24</th>\n",
       "      <td>22.30</td>\n",
       "      <td>-6.06</td>\n",
       "      <td>-750.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22 15:12:25</th>\n",
       "      <td>-51.03</td>\n",
       "      <td>-9.98</td>\n",
       "      <td>1274.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 02:58:47</th>\n",
       "      <td>-49.55</td>\n",
       "      <td>-5.71</td>\n",
       "      <td>907.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 02:58:48</th>\n",
       "      <td>-91.97</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>1643.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 02:58:50</th>\n",
       "      <td>-50.92</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>853.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 02:58:51</th>\n",
       "      <td>-106.55</td>\n",
       "      <td>-6.79</td>\n",
       "      <td>2238.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 02:58:52</th>\n",
       "      <td>-29.30</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>278.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 02:58:53</th>\n",
       "      <td>-21.51</td>\n",
       "      <td>-4.31</td>\n",
       "      <td>1012.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 02:58:53</th>\n",
       "      <td>-15.14</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-792.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 02:58:54</th>\n",
       "      <td>-16.20</td>\n",
       "      <td>-6.27</td>\n",
       "      <td>-1082.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 02:58:55</th>\n",
       "      <td>-54.78</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>1560.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 02:58:55</th>\n",
       "      <td>-102.08</td>\n",
       "      <td>-10.89</td>\n",
       "      <td>2445.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 02:58:56</th>\n",
       "      <td>109.07</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-3843.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 02:58:57</th>\n",
       "      <td>186.67</td>\n",
       "      <td>-9.98</td>\n",
       "      <td>-8433.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 02:58:57</th>\n",
       "      <td>-267.51</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>2615.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 02:58:58</th>\n",
       "      <td>-277.18</td>\n",
       "      <td>-6.06</td>\n",
       "      <td>2140.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Swap  Commission   Profit\n",
       "Time                                            \n",
       "2023-12-20 18:32:00    5.80       -3.50  -819.67\n",
       "2023-12-20 18:32:00  -16.49       -3.50   461.36\n",
       "2023-12-20 18:32:01  -53.72       -3.50   812.63\n",
       "2023-12-20 18:32:01   -1.65       -3.50   658.71\n",
       "2023-12-20 18:32:02   38.89       -3.50  1941.65\n",
       "2023-12-20 18:32:02   -6.16       -3.50   915.67\n",
       "2023-12-20 18:32:03  -27.88       -3.50  -420.91\n",
       "2023-12-22 15:12:18   -8.29       -5.71   693.73\n",
       "2023-12-22 15:12:19   -3.30      -10.89 -2455.53\n",
       "2023-12-22 15:12:20   -2.71       -6.27  -648.48\n",
       "2023-12-22 15:12:21   -3.60       -4.31   436.55\n",
       "2023-12-22 15:12:21  -17.82       -6.79   397.13\n",
       "2023-12-22 15:12:24   22.30       -6.06  -750.24\n",
       "2023-12-22 15:12:25  -51.03       -9.98  1274.09\n",
       "2023-12-29 02:58:47  -49.55       -5.71   907.07\n",
       "2023-12-29 02:58:48  -91.97       -3.50  1643.09\n",
       "2023-12-29 02:58:50  -50.92       -3.50   853.81\n",
       "2023-12-29 02:58:51 -106.55       -6.79  2238.90\n",
       "2023-12-29 02:58:52  -29.30       -3.50   278.28\n",
       "2023-12-29 02:58:53  -21.51       -4.31  1012.42\n",
       "2023-12-29 02:58:53  -15.14       -3.50  -792.37\n",
       "2023-12-29 02:58:54  -16.20       -6.27 -1082.81\n",
       "2023-12-29 02:58:55  -54.78       -3.50  1560.26\n",
       "2023-12-29 02:58:55 -102.08      -10.89  2445.07\n",
       "2023-12-29 02:58:56  109.07       -3.50 -3843.87\n",
       "2023-12-29 02:58:57  186.67       -9.98 -8433.84\n",
       "2023-12-29 02:58:57 -267.51       -3.50  2615.22\n",
       "2023-12-29 02:58:58 -277.18       -6.06  2140.06"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "4bb963db-ff74-4c20-a19e-60694e6e339b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'00:00:00'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:213\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '00:00:00'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[773], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m hist_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSwap\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCommission\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfit\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m hist_df \u001b[38;5;241m=\u001b[39m hist_df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mhist_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1393\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[0;32m   1342\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4236\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4234\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[0;32m   4235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4236\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   4239\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '00:00:00'"
     ]
    }
   ],
   "source": [
    "hist_df = pd.DataFrame(new_lst)\n",
    "hist_df.columns = 'Time', 'Swap', 'Commission', 'Profit'\n",
    "hist_df = hist_df.set_index('Time')\n",
    "hist_df.loc[start_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "d45c5bbc-a1ea-4b5b-96d0-550217020ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt5.positions_get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "18c1e716-5c67-4baf-987a-c0b2aa2c3872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_position(position):\n",
    "\n",
    "    tick = mt5.symbol_info_tick(position.symbol)\n",
    "\n",
    "    request = {\n",
    "        \"action\" : mt5.TRADE_ACTION_DEAL,\n",
    "        \"position\": position.ticket,\n",
    "        \"symbol\": position.symbol,\n",
    "        \"volume\": position.volume,\n",
    "        \"type\": mt5.ORDER_TYPE_BUY if position.type == 1 else mt5.ORDER_TYPE_SELL,\n",
    "        \"price\": tick.ask if position.type == 1 else tick.bid,\n",
    "        \"deviation\": 20,\n",
    "        \"magic\": 100,\n",
    "        \"comment\": 'Regres Close',\n",
    "        'type_time': mt5.ORDER_TIME_GTC,\n",
    "        'type_filling':mt5.ORDER_FILLING_IOC,\n",
    "\n",
    "        }\n",
    "    result = mt5.order_send(request)\n",
    "    \n",
    "def close_all():\n",
    "    close_positions = []\n",
    "    open_positions = mt5.positions_get()\n",
    "    open_positions\n",
    "    for i in open_positions:\n",
    "        close_positions.append(i)\n",
    "        \n",
    "    for pos in close_positions:\n",
    "        close_position(pos)\n",
    "        \n",
    "class ProfitLossControl:\n",
    "    \n",
    "    def __init__(self, max_daily_dd, profit_threshold, hedging_threshold, starting_equity):\n",
    "        self.max_daily_dd = max_daily_dd\n",
    "        self.profit_threshold = profit_threshold\n",
    "        self.hedging_threshold = hedging_threshold\n",
    "        self.starting_equity = starting_equity\n",
    "    \n",
    "    def start_equity(self):\n",
    "\n",
    "        gmt_plus_2 = pytz.timezone('EET')  # Eastern European Time is typically GMT+2\n",
    "\n",
    "        # Get the current time in UTC and convert it to GMT+2\n",
    "        now_utc = datetime.now(timezone.utc)\n",
    "        time = now_utc.astimezone(gmt_plus_2)\n",
    "        now_gmt_plus_2 = now_utc.astimezone(gmt_plus_2)\n",
    "\n",
    "        # Create a datetime object for the reset time (00:00:01) on the same day in GMT+2\n",
    "        reset_time_today = now_gmt_plus_2.replace(hour=0, minute=0)\n",
    "\n",
    "        if now_gmt_plus_2 != reset_time_today:\n",
    "            info = mt5.account_info()\n",
    "            start_equity = info.equity\n",
    "            print(f\"Starting equity is {start_equity}\")\n",
    "            return start_equity\n",
    "\n",
    "        else:\n",
    "            print(f\"{countdown} remaining until equity reset\")\n",
    "            return countdown \n",
    "\n",
    "    def day_pnl(self, start_equity): # Return current days equity drawdow / profit as a percentage from the start of the day. \n",
    "        \n",
    "        # Define the GMT+2 timezone\n",
    "        gmt_plus_2 = pytz.timezone('EET')  # Eastern European Time is typically GMT+2\n",
    "\n",
    "        # Get the current time in UTC and convert it to GMT+2\n",
    "        now_utc = datetime.now(timezone.utc)\n",
    "        time = now_utc.astimezone(gmt_plus_2)\n",
    "        now_gmt_plus_2 = now_utc.astimezone(gmt_plus_2)\n",
    "\n",
    "        # Create a datetime object for the reset time (00:00:01) on the same day in GMT+2\n",
    "        reset_time_today = now_gmt_plus_2.replace(hour=0, minute=0, second=1, microsecond=0)\n",
    "\n",
    "        # Calculate the countdown to the reset time\n",
    "        if now_gmt_plus_2 >= reset_time_today:\n",
    "            # If the current time is after the reset time, calculate the countdown to the next day's reset time\n",
    "            reset_time_tomorrow = reset_time_today + timedelta(days=1)\n",
    "            countdown = reset_time_tomorrow - now_gmt_plus_2\n",
    "        else:\n",
    "            # If the current time is before today's reset time, calculate the countdown to today's reset time\n",
    "            countdown = reset_time_today - now_gmt_plus_2\n",
    "        \n",
    "        account_info = mt5.account_info()\n",
    "        equity = account_info.balance + account_info.profit\n",
    "        \n",
    "        day_pnl = equity - start_equity\n",
    "\n",
    "        print(day_pnl)\n",
    "        print(f\"Time until next reset: {countdown}\")\n",
    "        \n",
    "        return int(day_pnl)\n",
    "        \n",
    "    def daily_dd_control(self, day_pnl): \n",
    "        \n",
    "        if day_pnl <= (self.max_daily_dd / 1.35):\n",
    "            print('Closing all positions for the day')\n",
    "            close_all()\n",
    "        else:\n",
    "            print(f'Threshold not reached. Current day pnl percent: {day_pnl}')\n",
    "        \n",
    "obj = ProfitLossControl(-0.03, 0.03, 0.00125, 190000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "eb456f8d-1e84-4492-91d2-39d0a26b6b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting equity is 5901.43\n"
     ]
    }
   ],
   "source": [
    "t1ab = obj.start_equity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "id": "0de14de8-24d6-4932-8353-ab9b9859ab8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=42558, microseconds=391449)"
      ]
     },
     "execution_count": 942,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "id": "fd8f2e3c-66fb-4796-a4b6-75baabcdc246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5300000000006548\n",
      "Time until next reset: 8:23:57.509222\n"
     ]
    }
   ],
   "source": [
    "day_equity = obj.day_pnl(t1ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "id": "f78d3763-aeea-4cd0-b72b-0e84e2a1aae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.819999999999709\n",
      "Time until next reset: 8:28:09.460358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 945,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.day_pnl(t1ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "id": "855b5734-2b62-4e8f-8316-bd694211b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_equity = -0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "id": "88317610-c536-4088-be74-71bef779ac7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing all positions for the day\n"
     ]
    }
   ],
   "source": [
    "obj.daily_dd_control(-0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "d716448c-9505-48bf-bc52-f7c609781b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_countdown():\n",
    "    gmt_plus_2 = pytz.timezone('EET')  # Eastern European Time is typically GMT+2\n",
    "\n",
    "    # Get the current time in UTC and convert it to GMT+2\n",
    "    now_utc = datetime.now(timezone.utc)\n",
    "    time = now_utc.astimezone(gmt_plus_2)\n",
    "    now_gmt_plus_2 = now_utc.astimezone(gmt_plus_2)\n",
    "\n",
    "    # Create a datetime object for the reset time (00:00:01) on the same day in GMT+2\n",
    "    reset_time_today = now_gmt_plus_2.replace(hour=0, minute=0)\n",
    "\n",
    "    if now_gmt_plus_2 == reset_time_today:\n",
    "        info = mt5.account_info()\n",
    "        start_equity = info.equity\n",
    "        print(f\"Starting equity is {start_equity}\")\n",
    "        return start_equity\n",
    "\n",
    "    else:\n",
    "        print(f\"{countdown} remaining until equity reset\")\n",
    "        return countdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "689b4123-889f-4c67-acfd-0b81becc4eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:49:18.391449 remaining until equity reset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=42558, microseconds=391449)"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_countdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1b2f80-d316-41db-a028-a9361848187c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cea60e3-acfc-423a-b2c3-cdfc767771d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d67d95-5805-4c0c-813d-9cd068d72690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abd9ca03-9187-4e73-8194-76744471f5c5",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "881009fd-9db0-48f3-a828-345f11bc5e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting AUDUSD.a's rates\n",
      "Getting USDCAD.a's rates\n",
      "Getting USDCHF.a's rates\n",
      "Getting GBPUSD.a's rates\n",
      "Getting USDJPY.a's rates\n",
      "Getting NZDUSD.a's rates\n",
      "Getting EURUSD.a's rates\n"
     ]
    }
   ],
   "source": [
    "combined_dfs_m = {}\n",
    "for country in count_codes:\n",
    "\n",
    "    # Define the endpoint parameters\n",
    "    flow = 'BIS,WS_EER_M,1.0'  # Example: Version 1.0 of the WS_EER_M domain, maintained by the BIS\n",
    "    key = f'M.N.N.{country[1]}'\n",
    "    start_period = '2000'  # Example: Start year 2000\n",
    "    end_period = '2025'  # Example: End year 2020\n",
    "    detail = 'full'  # Example: All data and documentation\n",
    "\n",
    "    # Construct the endpoint URL\n",
    "    endpoint_url = f'{base_url}/data/{flow}/{key}/all'\n",
    "\n",
    "    # Define the query parameters\n",
    "    query_params = {\n",
    "        'startPeriod': start_period,\n",
    "        'endPeriod': end_period,\n",
    "        'detail': detail\n",
    "    }\n",
    "\n",
    "    # Make the GET request\n",
    "    response = requests.get(endpoint_url, params=query_params)\n",
    "\n",
    "    # Check for a successful response\n",
    "    if response.status_code == 200:\n",
    "        # Assign the text of the response to xml_data\n",
    "        xml_data = response.text\n",
    "\n",
    "        # Parse the XML data\n",
    "        root = ET.fromstring(xml_data)\n",
    "\n",
    "        # Initialize empty lists to store the data\n",
    "        time_periods = []\n",
    "        obs_values = []\n",
    "\n",
    "        # Iterate through the XML and extract the desired information\n",
    "        for obs in root.findall(\".//Obs\"):\n",
    "            time_period = obs.get('TIME_PERIOD')\n",
    "            obs_value = obs.get('OBS_VALUE')\n",
    "            time_periods.append(time_period)\n",
    "            obs_values.append(obs_value)\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'Time_Period': time_periods,\n",
    "            'OBS_Value': obs_values\n",
    "        })\n",
    "\n",
    "        df['OBS_Value'] = df['OBS_Value'].replace('NaN', np.nan)\n",
    "        # Drop rows with NaN values\n",
    "        df.dropna(subset=['OBS_Value'], inplace=True)\n",
    "        df['OBS_Value'] = df['OBS_Value'].astype(float)\n",
    "        df['Time_Period'] = pd.to_datetime(df['Time_Period'])\n",
    "        \n",
    "        df = df.set_index('Time_Period')\n",
    "        print(f\"Getting {country[0]}'s rates\")\n",
    "        rates = get_rates(country[0], mt5.TIMEFRAME_D1, 2500)\n",
    "        \n",
    "        combined = pd.concat([df[-len(rates):], rates['close']], join = 'outer', axis = 1)\n",
    "        \n",
    "        combined_dfs_m[country[1]] = combined.dropna()\n",
    "\n",
    "    else:\n",
    "        print(f'Failed to retrieve data: {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "id": "36866c12-5361-4226-8630-1d9dffbee556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting AUDUSD.a's rates\n",
      "Getting USDCAD.a's rates\n",
      "Getting USDCHF.a's rates\n",
      "Getting GBPUSD.a's rates\n",
      "Getting USDJPY.a's rates\n",
      "Getting NZDUSD.a's rates\n",
      "Getting EURUSD.a's rates\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "combined_dfs = {}\n",
    "\n",
    "# Define the base URL for the BIS Stats API\n",
    "base_url = 'https://stats.bis.org/api/v1'\n",
    "\n",
    "count_codes = [['AUDUSD.a','AU'], ['USDCAD.a', 'CA'],\n",
    "               ['USDCHF.a','CH'], ['GBPUSD.a', 'GB'],\n",
    "               ['USDJPY.a', 'JP'], ['NZDUSD.a', 'NZ'], \n",
    "               ['EURUSD.a', 'XM']]\n",
    "\n",
    "for country in count_codes:\n",
    "\n",
    "    # Define the endpoint parameters\n",
    "    flow = 'BIS,WS_EER_D,1.0'  # Example: Version 1.0 of the WS_EER_M domain, maintained by the BIS\n",
    "    key = f'D.N.N.{country[1]}'\n",
    "    start_period = '2000'  # Example: Start year 2000\n",
    "    end_period = '2025'  # Example: End year 2020\n",
    "    detail = 'full'  # Example: All data and documentation\n",
    "\n",
    "    # Construct the endpoint URL\n",
    "    endpoint_url = f'{base_url}/data/{flow}/{key}/all'\n",
    "\n",
    "    # Define the query parameters\n",
    "    query_params = {\n",
    "        'startPeriod': start_period,\n",
    "        'endPeriod': end_period,\n",
    "        'detail': detail\n",
    "    }\n",
    "\n",
    "    # Make the GET request\n",
    "    response = requests.get(endpoint_url, params=query_params)\n",
    "\n",
    "    # Check for a successful response\n",
    "    if response.status_code == 200:\n",
    "        # Assign the text of the response to xml_data\n",
    "        xml_data = response.text\n",
    "\n",
    "        # Parse the XML data\n",
    "        root = ET.fromstring(xml_data)\n",
    "\n",
    "        # Initialize empty lists to store the data\n",
    "        time_periods = []\n",
    "        obs_values = []\n",
    "\n",
    "        # Iterate through the XML and extract the desired information\n",
    "        for obs in root.findall(\".//Obs\"):\n",
    "            time_period = obs.get('TIME_PERIOD')\n",
    "            obs_value = obs.get('OBS_VALUE')\n",
    "            time_periods.append(time_period)\n",
    "            obs_values.append(obs_value)\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'Time_Period': time_periods,\n",
    "            'OBS_Value': obs_values\n",
    "        })\n",
    "\n",
    "        df['OBS_Value'] = df['OBS_Value'].replace('NaN', np.nan)\n",
    "        # Drop rows with NaN values\n",
    "        df.dropna(subset=['OBS_Value'], inplace=True)\n",
    "        df['OBS_Value'] = df['OBS_Value'].astype(float)\n",
    "        df['Time_Period'] = pd.to_datetime(df['Time_Period'])\n",
    "        \n",
    "        df = df.set_index('Time_Period')\n",
    "        print(f\"Getting {country[0]}'s rates\")\n",
    "        rates = get_rates(country[0], mt5.TIMEFRAME_D1, 2500)\n",
    "        \n",
    "        combined = pd.concat([df[-len(rates):], rates['close']], join = 'outer', axis = 1)\n",
    "        \n",
    "        combined_dfs[country[1]] = combined.dropna()\n",
    "\n",
    "    else:\n",
    "        print(f'Failed to retrieve data: {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "id": "637738ae-9c2f-4b94-b2b8-1ab37478701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Expected Returns\n",
    "weekly_dfs = {}\n",
    "features = ['OBS_Value', 'close']\n",
    "\n",
    "for name, dfs in combined_dfs.items():\n",
    "    df = combined_dfs[name]\n",
    "    # Assuming 'df' is your DataFrame\n",
    "    df['date'] = pd.to_datetime(df.index)\n",
    "    df.set_index('date', inplace=True)\n",
    "\n",
    "    # Resample to get the last value of each week\n",
    "    weekly = df.resample('W').last()\n",
    "    weekly_dfs[name] = weekly\n",
    "    \n",
    "    # Add a new column for Monthly OBS Values in the weekly DataFrame\n",
    "    weekly_dfs[name]['Monthly_OBS_Value'] = np.nan\n",
    "\n",
    "    # Iterate through the monthly DataFrame\n",
    "    for date, row in combined_dfs_m[name].iterrows():\n",
    "        # Find all weekly dates that are in the same month and year as the monthly date\n",
    "        mask = (weekly_dfs[name].index.month == date.month) & (weekly_dfs[name].index.year == date.year)\n",
    "        weekly_dfs[name].loc[mask, 'Monthly_OBS_Value'] = row['OBS_Value']\n",
    "\n",
    "    # Forward fill the NaN values in the Monthly_OBS_Value column\n",
    "    weekly_dfs[name]['Monthly_OBS_Value'] = weekly_dfs[name]['Monthly_OBS_Value'].ffill()\n",
    "    \n",
    "for df in weekly_dfs.values():\n",
    "    df['W_EER_ret'] = df['OBS_Value'].pct_change()\n",
    "    df['M_EER_ret'] = df['Monthly_OBS_Value'].pct_change()\n",
    "    df['close_ret'] = df['close'].pct_change()\n",
    "    df['ret_diff'] = df['close_ret'] - df['W_EER_ret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "f6d95165-6f24-40e8-a770-aeaccb3fd81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBS_Value</th>\n",
       "      <th>close</th>\n",
       "      <th>Monthly_OBS_Value</th>\n",
       "      <th>W_EER_ret</th>\n",
       "      <th>M_EER_ret</th>\n",
       "      <th>close_ret</th>\n",
       "      <th>ret_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-06-08</th>\n",
       "      <td>121.06</td>\n",
       "      <td>0.93325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-15</th>\n",
       "      <td>121.81</td>\n",
       "      <td>0.93998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.001016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-22</th>\n",
       "      <td>121.76</td>\n",
       "      <td>0.93867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001394</td>\n",
       "      <td>-0.000983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-29</th>\n",
       "      <td>121.67</td>\n",
       "      <td>0.94239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>0.004702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-06</th>\n",
       "      <td>120.95</td>\n",
       "      <td>0.93628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006484</td>\n",
       "      <td>-0.000566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-10</th>\n",
       "      <td>102.83</td>\n",
       "      <td>0.65758</td>\n",
       "      <td>102.04</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.014861</td>\n",
       "      <td>-0.013017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-17</th>\n",
       "      <td>103.38</td>\n",
       "      <td>0.67018</td>\n",
       "      <td>102.04</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019161</td>\n",
       "      <td>0.013813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-24</th>\n",
       "      <td>104.56</td>\n",
       "      <td>0.67972</td>\n",
       "      <td>102.04</td>\n",
       "      <td>0.011414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014235</td>\n",
       "      <td>0.002821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>104.12</td>\n",
       "      <td>0.68044</td>\n",
       "      <td>102.04</td>\n",
       "      <td>-0.004208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.005267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-07</th>\n",
       "      <td>104.55</td>\n",
       "      <td>0.67610</td>\n",
       "      <td>102.04</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006378</td>\n",
       "      <td>-0.010508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            OBS_Value    close  Monthly_OBS_Value  W_EER_ret  M_EER_ret  \\\n",
       "date                                                                      \n",
       "2014-06-08     121.06  0.93325                NaN        NaN        NaN   \n",
       "2014-06-15     121.81  0.93998                NaN   0.006195        NaN   \n",
       "2014-06-22     121.76  0.93867                NaN  -0.000410        NaN   \n",
       "2014-06-29     121.67  0.94239                NaN  -0.000739        NaN   \n",
       "2014-07-06     120.95  0.93628                NaN  -0.005918        NaN   \n",
       "...               ...      ...                ...        ...        ...   \n",
       "2023-12-10     102.83  0.65758             102.04  -0.001844        0.0   \n",
       "2023-12-17     103.38  0.67018             102.04   0.005349        0.0   \n",
       "2023-12-24     104.56  0.67972             102.04   0.011414        0.0   \n",
       "2023-12-31     104.12  0.68044             102.04  -0.004208        0.0   \n",
       "2024-01-07     104.55  0.67610             102.04   0.004130        0.0   \n",
       "\n",
       "            close_ret  ret_diff  \n",
       "date                             \n",
       "2014-06-08        NaN       NaN  \n",
       "2014-06-15   0.007211  0.001016  \n",
       "2014-06-22  -0.001394 -0.000983  \n",
       "2014-06-29   0.003963  0.004702  \n",
       "2014-07-06  -0.006484 -0.000566  \n",
       "...               ...       ...  \n",
       "2023-12-10  -0.014861 -0.013017  \n",
       "2023-12-17   0.019161  0.013813  \n",
       "2023-12-24   0.014235  0.002821  \n",
       "2023-12-31   0.001059  0.005267  \n",
       "2024-01-07  -0.006378 -0.010508  \n",
       "\n",
       "[501 rows x 7 columns]"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_dfs['AU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "050f8e40-1fc1-4fa2-819b-a63a407789f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_update = {}\n",
    "\n",
    "for name, df in weekly_dfs.items():\n",
    "    last_update[name] = df['W_EER_ret'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d7cc9a3d-ec1e-41ad-b0e2-ba7bd99684e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_update.keys()\n",
    "symbols = ['AUDUSD.a', 'USDCAD.a', 'USDCHF.a', 'GBPUSD.a', 'USDJPY.a', 'NZDUSD.a', 'EURUSD.a']\n",
    "\n",
    "last_update = {symbols[i]: value for i, (key, value) in enumerate(last_update.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "49e1dbf8-1943-4b69-a5d1-00adca5a199d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AUDUSD.a': 0.005348633667217717,\n",
       " 'USDCAD.a': 0.010298049311813218,\n",
       " 'USDCHF.a': -0.00220731061274948,\n",
       " 'GBPUSD.a': 0.0011580775911985697,\n",
       " 'USDJPY.a': 0.00992167101827679,\n",
       " 'NZDUSD.a': -0.0012782694198624212,\n",
       " 'EURUSD.a': 0.0059632100262785315}"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1637ef-bc47-4d0e-8307-babb2ff29771",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Order Sending / Closing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "526bf68e-fcf1-44af-a420-92c614b65896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def close_all():\n",
    "    close_positions = []\n",
    "    open_positions = mt5.positions_get()\n",
    "    open_positions\n",
    "    for i in open_positions:\n",
    "        close_positions.append(i)\n",
    "        \n",
    "    for pos in close_positions:\n",
    "        close_position(pos)\n",
    "        \n",
    "def close_position(position, comment):\n",
    "    \n",
    "    tick = mt5.symbol_info_tick(position.symbol)\n",
    "\n",
    "    request = {\n",
    "        \"action\" : mt5.TRADE_ACTION_DEAL,\n",
    "        \"position\": position.ticket,\n",
    "        \"symbol\": position.symbol,\n",
    "        \"volume\": position.volume,\n",
    "        \"type\": mt5.ORDER_TYPE_BUY if position.type == 1 else mt5.ORDER_TYPE_SELL,\n",
    "        \"price\": tick.ask if position.type == 1 else tick.bid,\n",
    "        \"deviation\": 20,\n",
    "        \"magic\": 100,\n",
    "        \"comment\": comment,\n",
    "        'type_time': mt5.ORDER_TIME_GTC,\n",
    "        'type_filling':mt5.ORDER_FILLING_IOC,\n",
    "\n",
    "        }\n",
    "    result = mt5.order_send(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc347626-7bf5-48a1-9ea6-d977d6dee598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def send_order(symbol, side, lot, comment):\n",
    "    \n",
    "    if side.lower() == 'sell':\n",
    "        order_type = mt5.ORDER_TYPE_SELL\n",
    "        price = mt5.symbol_info_tick(symbol).bid\n",
    "    elif side.lower() == 'buy':\n",
    "        order_type = mt5.ORDER_TYPE_BUY\n",
    "        price = mt5.symbol_info_tick(symbol).ask\n",
    "    \n",
    "    request = {\n",
    "        \"action\": mt5.TRADE_ACTION_DEAL,\n",
    "        \"symbol\": symbol,\n",
    "        \"volume\": lot,\n",
    "        \"type\": order_type,\n",
    "        \"price\": price,\n",
    "        \"deviation\": 5,\n",
    "        \"magic\": 234000,\n",
    "        \"comment\": comment,\n",
    "        \"type_time\": mt5.ORDER_TIME_GTC,\n",
    "        \"type_filling\": mt5.ORDER_FILLING_IOC,\n",
    "    }\n",
    "    result = mt5.order_send(request)\n",
    "    result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "c7099224-0fc6-4b1f-bc77-b247a4673371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TradePosition(ticket=548724611, time=1703057580, time_msc=1703057580167, time_update=1703057580, time_update_msc=1703057580167, type=0, magic=234000, identifier=548724611, reason=3, volume=1.0, price_open=0.67699, sl=0.0, tp=0.0, price_current=0.67972, swap=-25.6, profit=401.35, symbol='AUDUSD.a', comment='EER', external_id='')\n",
      "TradePosition(ticket=548724617, time=1703057580, time_msc=1703057580645, time_update=1703057580, time_update_msc=1703057580645, type=1, magic=234000, identifier=548724617, reason=3, volume=1.0, price_open=1.33499, sl=0.0, tp=0.0, price_current=1.32675, swap=-27.42, profit=913.26, symbol='USDCAD.a', comment='EER', external_id='')\n",
      "TradePosition(ticket=548724638, time=1703057581, time_msc=1703057581125, time_update=1703057581, time_update_msc=1703057581125, type=0, magic=234000, identifier=548724638, reason=3, volume=1.0, price_open=0.86149, sl=0.0, tp=0.0, price_current=0.85574, swap=54.44, profit=-988.79, symbol='USDCHF.a', comment='EER', external_id='')\n",
      "TradePosition(ticket=548724659, time=1703057581, time_msc=1703057581612, time_update=1703057581, time_update_msc=1703057581612, type=0, magic=234000, identifier=548724659, reason=3, volume=1.0, price_open=1.2721, sl=0.0, tp=0.0, price_current=1.26972, swap=-14.73, profit=-350.14, symbol='GBPUSD.a', comment='EER', external_id='')\n",
      "TradePosition(ticket=548724664, time=1703057582, time_msc=1703057582093, time_update=1703057582, time_update_msc=1703057582093, type=1, magic=234000, identifier=548724664, reason=3, volume=1.0, price_open=143.647, sl=0.0, tp=0.0, price_current=142.482, swap=-134.02, profit=1201.79, symbol='USDJPY.a', comment='EER', external_id='')\n",
      "TradePosition(ticket=548724682, time=1703057582, time_msc=1703057582568, time_update=1703057582, time_update_msc=1703057582568, type=1, magic=234000, identifier=548724682, reason=3, volume=1.0, price_open=0.62766, sl=0.0, tp=0.0, price_current=0.62979, swap=-7.61, profit=-313.36, symbol='NZDUSD.a', comment='EER', external_id='')\n",
      "TradePosition(ticket=548724687, time=1703057583, time_msc=1703057583048, time_update=1703057583, time_update_msc=1703057583048, type=0, magic=234000, identifier=548724687, reason=3, volume=1.0, price_open=1.09656, sl=0.0, tp=0.0, price_current=1.10137, swap=-46.24, profit=707.13, symbol='EURUSD.a', comment='EER', external_id='')\n",
      "TradePosition(ticket=550651507, time=1703218352, time_msc=1703218352298, time_update=1703218352, time_update_msc=1703218352298, type=0, magic=234000, identifier=550651507, reason=3, volume=1.63, price_open=0.67906, sl=0.0, tp=0.0, price_current=0.67972, swap=-8.29, profit=158.16, symbol='AUDUSD.a', comment='EER', external_id='')\n",
      "TradePosition(ticket=550651510, time=1703218352, time_msc=1703218352798, time_update=1703218352, time_update_msc=1703218352798, type=1, magic=234000, identifier=550651510, reason=3, volume=3.11, price_open=1.32805, sl=0.0, tp=0.0, price_current=1.32675, swap=-17.03, profit=448.1, symbol='USDCAD.a', comment='EER', external_id='')\n",
      "TradePosition(ticket=550651512, time=1703218353, time_msc=1703218353289, time_update=1703218353, time_update_msc=1703218353289, type=0, magic=234000, identifier=550651512, reason=3, volume=2.85, price_open=0.85643, sl=0.0, tp=0.0, price_current=0.85574, swap=30.98, profit=-338.17, symbol='USDCHF.a', comment='EER', external_id='')\n",
      "TradePosition(ticket=550651513, time=1703218353, time_msc=1703218353809, time_update=1703218353, time_update_msc=1703218353809, type=0, magic=234000, identifier=550651513, reason=3, volume=1.23, price_open=1.26836, sl=0.0, tp=0.0, price_current=1.26972, swap=-3.6, profit=245.92, symbol='GBPUSD.a', comment='EER', external_id='')\n",
      "TradePosition(ticket=550651516, time=1703218354, time_msc=1703218354458, time_update=1703218354, time_update_msc=1703218354458, type=1, magic=234000, identifier=550651516, reason=3, volume=1.73, price_open=142.32, sl=0.0, tp=0.0, price_current=142.482, swap=-46.26, profit=-289.7, symbol='USDJPY.a', comment='EER', external_id='')\n",
      "TradePosition(ticket=550651518, time=1703218355, time_msc=1703218355058, time_update=1703218355, time_update_msc=1703218355058, type=1, magic=234000, identifier=550651518, reason=3, volume=1.79, price_open=0.62888, sl=0.0, tp=0.0, price_current=0.62979, swap=-2.71, profit=-239.64, symbol='NZDUSD.a', comment='EER', external_id='')\n",
      "TradePosition(ticket=550651519, time=1703218355, time_msc=1703218355676, time_update=1703218355, time_update_msc=1703218355676, type=0, magic=234000, identifier=550651519, reason=3, volume=1.94, price_open=1.09986, sl=0.0, tp=0.0, price_current=1.10137, swap=-17.83, profit=430.66, symbol='EURUSD.a', comment='EER', external_id='')\n"
     ]
    }
   ],
   "source": [
    "all_positions = mt5.positions_get()\n",
    "for position in all_positions:\n",
    "    print(position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63cea26-b75d-41a1-adf3-ecd9b8eb21a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Risk Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ca880-4e1d-4443-a037-b15c4c4e7dd6",
   "metadata": {},
   "source": [
    "**High level approach**\n",
    "\n",
    "ARIMA model to forecast EER values (from week-1) to be used as a feature in a regression model along with the EER vals for week0 along with the EER value difference vs EER value forecasted\n",
    "\n",
    "Obtain an expected return (range?) to then create an MVO portfolio to run in a monte carlo simulation to obtain the most optimal weightings/allocation (optimised for sharpe ratio)\n",
    "\n",
    "Steps\n",
    "1. Create ARIMA and EER Val forecasts \n",
    "    - Run statistical analysis to incorporate differing variations \n",
    "2. Train a regression model on data to obtain expected returns\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a126c2-9b00-4df2-95f8-9b73b03482db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f81a7a-9371-4d4d-9599-b26fd8e67e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50ba23ec-a7da-4e32-b1df-7eb78f597018",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ARIMA value\n",
    "\n",
    "Forecast next EER value for each currency for the next week. Use forecasted EER values AND the difference between forecasted EER values vs actual as features for linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "49914f06-233d-43aa-b37a-c29e80398aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import warnings\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_arima_model_aic_bic(series, arima_order):\n",
    "    '''Evaluates ARIMA model for AIC and BIC'''\n",
    "    try:\n",
    "        model = ARIMA(series, order=arima_order)\n",
    "        model_fit = model.fit()\n",
    "        aic = model_fit.aic\n",
    "        bic = model_fit.bic\n",
    "        return aic, bic\n",
    "    except Exception as e:\n",
    "        print(f'Error with ARIMA order {arima_order}: {e}')\n",
    "        return float('inf'), float('inf')\n",
    "\n",
    "def find_best_arima_model(series, p_values, d_values, q_values):\n",
    "    '''Find the best ARIMA model based on AIC and BIC'''\n",
    "    best_aic, best_bic, best_cfg = float(\"inf\"), float(\"inf\"), None\n",
    "    for p, d, q in itertools.product(p_values, d_values, q_values):\n",
    "        order = (p, d, q)\n",
    "        aic, bic = evaluate_arima_model_aic_bic(series, order)\n",
    "        if aic < best_aic or bic < best_bic:\n",
    "            best_aic, best_bic, best_cfg = aic, bic, order\n",
    "            print(f'ARIMA{order} AIC: {aic}, BIC: {bic}')\n",
    "    print(f'Best ARIMA{best_cfg} AIC: {best_aic}, BIC: {best_bic}')\n",
    "    return best_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "51449762-cb9b-4b77-8084-2633d42e0cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBS_Value</th>\n",
       "      <th>close</th>\n",
       "      <th>Monthly_OBS_Value</th>\n",
       "      <th>W_EER_ret</th>\n",
       "      <th>M_EER_ret</th>\n",
       "      <th>close_ret</th>\n",
       "      <th>ret_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-05-25</th>\n",
       "      <td>118.63</td>\n",
       "      <td>1.08603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-01</th>\n",
       "      <td>119.35</td>\n",
       "      <td>1.08438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001519</td>\n",
       "      <td>-0.007589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-08</th>\n",
       "      <td>118.37</td>\n",
       "      <td>1.09316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>0.016308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-15</th>\n",
       "      <td>119.26</td>\n",
       "      <td>1.08551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006998</td>\n",
       "      <td>-0.014517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-22</th>\n",
       "      <td>119.58</td>\n",
       "      <td>1.07576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008982</td>\n",
       "      <td>-0.011665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-19</th>\n",
       "      <td>100.03</td>\n",
       "      <td>1.37184</td>\n",
       "      <td>100.13</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005870</td>\n",
       "      <td>-0.008576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-26</th>\n",
       "      <td>100.19</td>\n",
       "      <td>1.36336</td>\n",
       "      <td>100.13</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006181</td>\n",
       "      <td>-0.007781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-03</th>\n",
       "      <td>101.12</td>\n",
       "      <td>1.34972</td>\n",
       "      <td>100.13</td>\n",
       "      <td>0.009282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010005</td>\n",
       "      <td>-0.019287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-10</th>\n",
       "      <td>100.99</td>\n",
       "      <td>1.35863</td>\n",
       "      <td>100.13</td>\n",
       "      <td>-0.001286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.007887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-17</th>\n",
       "      <td>102.03</td>\n",
       "      <td>1.33796</td>\n",
       "      <td>100.13</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.015214</td>\n",
       "      <td>-0.025512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            OBS_Value    close  Monthly_OBS_Value  W_EER_ret  M_EER_ret  \\\n",
       "date                                                                      \n",
       "2014-05-25     118.63  1.08603                NaN        NaN        NaN   \n",
       "2014-06-01     119.35  1.08438                NaN   0.006069        NaN   \n",
       "2014-06-08     118.37  1.09316                NaN  -0.008211        NaN   \n",
       "2014-06-15     119.26  1.08551                NaN   0.007519        NaN   \n",
       "2014-06-22     119.58  1.07576                NaN   0.002683        NaN   \n",
       "...               ...      ...                ...        ...        ...   \n",
       "2023-11-19     100.03  1.37184             100.13   0.002706        0.0   \n",
       "2023-11-26     100.19  1.36336             100.13   0.001600        0.0   \n",
       "2023-12-03     101.12  1.34972             100.13   0.009282        0.0   \n",
       "2023-12-10     100.99  1.35863             100.13  -0.001286        0.0   \n",
       "2023-12-17     102.03  1.33796             100.13   0.010298        0.0   \n",
       "\n",
       "            close_ret  ret_diff  \n",
       "date                             \n",
       "2014-05-25        NaN       NaN  \n",
       "2014-06-01  -0.001519 -0.007589  \n",
       "2014-06-08   0.008097  0.016308  \n",
       "2014-06-15  -0.006998 -0.014517  \n",
       "2014-06-22  -0.008982 -0.011665  \n",
       "...               ...       ...  \n",
       "2023-11-19  -0.005870 -0.008576  \n",
       "2023-11-26  -0.006181 -0.007781  \n",
       "2023-12-03  -0.010005 -0.019287  \n",
       "2023-12-10   0.006601  0.007887  \n",
       "2023-12-17  -0.015214 -0.025512  \n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_dfs['CA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "23c91959-2266-41ad-8571-5fb8ab210317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 data points ran\n",
      "200 data points ran\n",
      "250 data points ran\n",
      "300 data points ran\n",
      "350 data points ran\n",
      "400 data points ran\n",
      "450 data points ran\n",
      "500 data points ran\n"
     ]
    }
   ],
   "source": [
    "arma_forecasts = {}\n",
    "\n",
    "series = weekly_dfs['AU']['OBS_Value']\n",
    "best_arima_order = (2, 1, 2)\n",
    "\n",
    "# Store the forecasts for each DataFrame\n",
    "forecasts = []\n",
    "\n",
    "# Iterate over the series, retraining the model on the most recent 100 data points and forecasting one step ahead\n",
    "for end in range(100, len(series)):\n",
    "    if end % 50 == 0:\n",
    "        print(f'{end + 50} data points ran')\n",
    "    train_data = series.iloc[end-100:end]\n",
    "    model = ARIMA(train_data, order=best_arima_order)\n",
    "    model_fit = model.fit()\n",
    "    forecast = model_fit.forecast(steps=1)\n",
    "    forecasts.append(forecast[0])\n",
    "\n",
    "arma_forecasts['AU'] = pd.DataFrame(forecasts, columns=['Forecast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "849ce322-13f0-456b-aabf-296395db870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = pd.DataFrame({'Forecast': [np.nan] * 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "97fef3c2-d2f0-4529-889c-b681cea7fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_eer_forecasts = pd.DataFrame(arma_forecasts['AU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "da64c08a-23d2-4e2c-bc44-9c62f7778635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBS_Value</th>\n",
       "      <th>close</th>\n",
       "      <th>Monthly_OBS_Value</th>\n",
       "      <th>W_EER_ret</th>\n",
       "      <th>M_EER_ret</th>\n",
       "      <th>close_ret</th>\n",
       "      <th>ret_diff</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>forecast_change</th>\n",
       "      <th>real_vs_forecast</th>\n",
       "      <th>r_v_f_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>111.70</td>\n",
       "      <td>0.77073</td>\n",
       "      <td>110.40</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001697</td>\n",
       "      <td>-0.006826</td>\n",
       "      <td>111.214791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485209</td>\n",
       "      <td>1.004363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>109.04</td>\n",
       "      <td>0.76055</td>\n",
       "      <td>110.40</td>\n",
       "      <td>-0.023814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.013208</td>\n",
       "      <td>0.010606</td>\n",
       "      <td>111.473987</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>-2.433987</td>\n",
       "      <td>0.978165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>105.77</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>110.40</td>\n",
       "      <td>-0.029989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.031780</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>108.946741</td>\n",
       "      <td>-0.022671</td>\n",
       "      <td>-3.176741</td>\n",
       "      <td>0.970841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>105.15</td>\n",
       "      <td>0.72697</td>\n",
       "      <td>110.40</td>\n",
       "      <td>-0.005862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.012779</td>\n",
       "      <td>-0.006917</td>\n",
       "      <td>106.230829</td>\n",
       "      <td>-0.024929</td>\n",
       "      <td>-1.080829</td>\n",
       "      <td>0.989826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>105.10</td>\n",
       "      <td>0.72208</td>\n",
       "      <td>110.40</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006727</td>\n",
       "      <td>-0.006251</td>\n",
       "      <td>105.973673</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>-0.873673</td>\n",
       "      <td>0.991756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>101.76</td>\n",
       "      <td>0.65142</td>\n",
       "      <td>102.04</td>\n",
       "      <td>0.010125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024213</td>\n",
       "      <td>0.014088</td>\n",
       "      <td>101.201704</td>\n",
       "      <td>-0.009347</td>\n",
       "      <td>0.558296</td>\n",
       "      <td>1.005517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>102.54</td>\n",
       "      <td>0.65801</td>\n",
       "      <td>102.04</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010116</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>101.155174</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>1.384826</td>\n",
       "      <td>1.013690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>103.02</td>\n",
       "      <td>0.66750</td>\n",
       "      <td>102.04</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014422</td>\n",
       "      <td>0.009741</td>\n",
       "      <td>103.072937</td>\n",
       "      <td>0.018959</td>\n",
       "      <td>-0.052937</td>\n",
       "      <td>0.999486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>102.83</td>\n",
       "      <td>0.65758</td>\n",
       "      <td>102.04</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.014861</td>\n",
       "      <td>-0.013017</td>\n",
       "      <td>102.985700</td>\n",
       "      <td>-0.000846</td>\n",
       "      <td>-0.155700</td>\n",
       "      <td>0.998488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>103.38</td>\n",
       "      <td>0.67018</td>\n",
       "      <td>102.04</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019161</td>\n",
       "      <td>0.013813</td>\n",
       "      <td>102.486666</td>\n",
       "      <td>-0.004846</td>\n",
       "      <td>0.893334</td>\n",
       "      <td>1.008717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OBS_Value    close  Monthly_OBS_Value  W_EER_ret  M_EER_ret  close_ret  \\\n",
       "100     111.70  0.77073             110.40   0.005129        0.0  -0.001697   \n",
       "101     109.04  0.76055             110.40  -0.023814        0.0  -0.013208   \n",
       "102     105.77  0.73638             110.40  -0.029989        0.0  -0.031780   \n",
       "103     105.15  0.72697             110.40  -0.005862        0.0  -0.012779   \n",
       "104     105.10  0.72208             110.40  -0.000476        0.0  -0.006727   \n",
       "..         ...      ...                ...        ...        ...        ...   \n",
       "495     101.76  0.65142             102.04   0.010125        0.0   0.024213   \n",
       "496     102.54  0.65801             102.04   0.007665        0.0   0.010116   \n",
       "497     103.02  0.66750             102.04   0.004681        0.0   0.014422   \n",
       "498     102.83  0.65758             102.04  -0.001844        0.0  -0.014861   \n",
       "499     103.38  0.67018             102.04   0.005349        0.0   0.019161   \n",
       "\n",
       "     ret_diff    Forecast  forecast_change  real_vs_forecast  r_v_f_ratio  \n",
       "100 -0.006826  111.214791              NaN          0.485209     1.004363  \n",
       "101  0.010606  111.473987         0.002331         -2.433987     0.978165  \n",
       "102 -0.001791  108.946741        -0.022671         -3.176741     0.970841  \n",
       "103 -0.006917  106.230829        -0.024929         -1.080829     0.989826  \n",
       "104 -0.006251  105.973673        -0.002421         -0.873673     0.991756  \n",
       "..        ...         ...              ...               ...          ...  \n",
       "495  0.014088  101.201704        -0.009347          0.558296     1.005517  \n",
       "496  0.002451  101.155174        -0.000460          1.384826     1.013690  \n",
       "497  0.009741  103.072937         0.018959         -0.052937     0.999486  \n",
       "498 -0.013017  102.985700        -0.000846         -0.155700     0.998488  \n",
       "499  0.013813  102.486666        -0.004846          0.893334     1.008717  \n",
       "\n",
       "[400 rows x 11 columns]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_df = pd.concat([nans, au_eer_forecasts]).reset_index(drop=True)\n",
    "t1 = weekly_dfs['AU'].reset_index(drop = True)\n",
    "t1a = pd.concat([t1, aligned_df], axis = 1).dropna()\n",
    "t1a['forecast_change'] = t1a['Forecast'].pct_change()\n",
    "t1a['real_vs_forecast'] = t1a['OBS_Value'] - t1a['Forecast']\n",
    "t1a['r_v_f_ratio'] = t1a['OBS_Value'] / t1a['Forecast']\n",
    "t1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "95582bf9-26e5-486d-be13-a1ad7c6525be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.02800769130933722"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1a['close_ret'].corr(t1a['real_vs_forecast_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "df24ee80-1e67-45d5-9876-507ffb19436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [['W_EER_ret', 'OBS_Value', 'Forecast', 'real_vs_forecast']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "0b1a22aa-dd36-4019-9317-3963eca6b3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "162446cf-1265-42e0-b082-dc05edad4ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = t1a[['r_v_f_ratio', 'W_EER_ret']]\n",
    "y = t1a['close_ret']\n",
    "\n",
    "X = scaler.fit_transform(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "53fe86e6-1868-482e-b7e0-8ee486989f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.00011891429932442882\n",
      "Coefficient of Determination (R^2): 0.43961711835228123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=42)\n",
    "\n",
    "# Create a Decision Tree Regressor model\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the performance metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Coefficient of Determination (R^2): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "e23547a7-9d05-4b54-85ea-992fa5240573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.00037561 -0.00193706]\n",
      "Mean squared error (MSE): 0.000152\n",
      "Coefficient of determination (R^2): -0.089668\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Creating the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions using the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients:', model.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error (MSE): %.6f' % mean_squared_error(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination (R^2): %.6f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "30b2a78f-90a6-41f7-b8e4-053997d936a1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating through AU\n",
      "150 data points ran\n",
      "200 data points ran\n",
      "250 data points ran\n",
      "300 data points ran\n",
      "350 data points ran\n",
      "400 data points ran\n",
      "450 data points ran\n",
      "500 data points ran\n",
      "Iterating through CA\n",
      "150 data points ran\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "LU decomposition error.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[399], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m train_data \u001b[38;5;241m=\u001b[39m series\u001b[38;5;241m.\u001b[39miloc[end\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m:end]\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m ARIMA(train_data, order\u001b[38;5;241m=\u001b[39mbest_arima_order)\n\u001b[1;32m---> 18\u001b[0m model_fit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m forecast \u001b[38;5;241m=\u001b[39m model_fit\u001b[38;5;241m.\u001b[39mforecast(steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m forecasts\u001b[38;5;241m.\u001b[39mappend(forecast[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\arima\\model.py:390\u001b[0m, in \u001b[0;36mARIMA.fit\u001b[1;34m(self, start_params, transformed, includes_fixed, method, method_kwargs, gls, gls_kwargs, cov_type, cov_kwds, return_params, low_memory)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     method_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 390\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    391\u001b[0m         return_params\u001b[38;5;241m=\u001b[39mreturn_params, low_memory\u001b[38;5;241m=\u001b[39mlow_memory,\n\u001b[0;32m    392\u001b[0m         cov_type\u001b[38;5;241m=\u001b[39mcov_type, cov_kwds\u001b[38;5;241m=\u001b[39mcov_kwds, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmethod_kwargs)\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_params:\n\u001b[0;32m    394\u001b[0m         res\u001b[38;5;241m.\u001b[39mfit_details \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mmlefit\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:704\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[1;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m         flags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhessian_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m optim_hessian\n\u001b[0;32m    703\u001b[0m     fargs \u001b[38;5;241m=\u001b[39m (flags,)\n\u001b[1;32m--> 704\u001b[0m     mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(MLEModel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(start_params, method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    705\u001b[0m                                        fargs\u001b[38;5;241m=\u001b[39mfargs,\n\u001b[0;32m    706\u001b[0m                                        maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m    707\u001b[0m                                        full_output\u001b[38;5;241m=\u001b[39mfull_output,\n\u001b[0;32m    708\u001b[0m                                        disp\u001b[38;5;241m=\u001b[39mdisp, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    709\u001b[0m                                        skip_hessian\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    711\u001b[0m \u001b[38;5;66;03m# Just return the fitted parameters if requested\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_params:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:563\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_t\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    562\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Optimizer()\n\u001b[1;32m--> 563\u001b[0m xopt, retvals, optim_settings \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mhessian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;66;03m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[0;32m    573\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:241\u001b[0m, in \u001b[0;36mOptimizer._fit\u001b[1;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[0;32m    238\u001b[0m     fit_funcs\u001b[38;5;241m.\u001b[39mupdate(extra_fit_funcs)\n\u001b[0;32m    240\u001b[0m func \u001b[38;5;241m=\u001b[39m fit_funcs[method]\n\u001b[1;32m--> 241\u001b[0m xopt, retvals \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m optim_settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: method, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_params\u001b[39m\u001b[38;5;124m'\u001b[39m: start_params,\n\u001b[0;32m    247\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: maxiter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_output\u001b[39m\u001b[38;5;124m'\u001b[39m: full_output,\n\u001b[0;32m    248\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfargs\u001b[39m\u001b[38;5;124m'\u001b[39m: fargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[0;32m    249\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretall\u001b[39m\u001b[38;5;124m'\u001b[39m: retall, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_fit_funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m: extra_fit_funcs}\n\u001b[0;32m    250\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:651\u001b[0m, in \u001b[0;36m_fit_lbfgs\u001b[1;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m approx_grad:\n\u001b[0;32m    649\u001b[0m     func \u001b[38;5;241m=\u001b[39m f\n\u001b[1;32m--> 651\u001b[0m retvals \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mfmin_l_bfgs_b(func, start_params, maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m    652\u001b[0m                                  callback\u001b[38;5;241m=\u001b[39mcallback, args\u001b[38;5;241m=\u001b[39mfargs,\n\u001b[0;32m    653\u001b[0m                                  bounds\u001b[38;5;241m=\u001b[39mbounds, disp\u001b[38;5;241m=\u001b[39mdisp,\n\u001b[0;32m    654\u001b[0m                                  \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kwargs)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[0;32m    657\u001b[0m     xopt, fopt, d \u001b[38;5;241m=\u001b[39m retvals\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:199\u001b[0m, in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    187\u001b[0m     disp \u001b[38;5;241m=\u001b[39m iprint\n\u001b[0;32m    188\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp,\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m'\u001b[39m: iprint,\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxcor\u001b[39m\u001b[38;5;124m'\u001b[39m: m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxls\u001b[39m\u001b[38;5;124m'\u001b[39m: maxls}\n\u001b[1;32m--> 199\u001b[0m res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args\u001b[38;5;241m=\u001b[39margs, jac\u001b[38;5;241m=\u001b[39mjac, bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m    200\u001b[0m                        \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n\u001b[0;32m    201\u001b[0m d \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjac\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    202\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    203\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfuncalls\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfev\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    204\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    205\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarnflag\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[0;32m    206\u001b[0m f \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:362\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    356\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 362\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    365\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:531\u001b[0m, in \u001b[0;36mLikelihoodModel.fit.<locals>.f\u001b[1;34m(params, *args)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(params, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloglike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nobs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:939\u001b[0m, in \u001b[0;36mMLEModel.loglike\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m complex_step:\n\u001b[0;32m    937\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minversion_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m INVERT_UNIVARIATE \u001b[38;5;241m|\u001b[39m SOLVE_LU\n\u001b[1;32m--> 939\u001b[0m loglike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssm\u001b[38;5;241m.\u001b[39mloglike(complex_step\u001b[38;5;241m=\u001b[39mcomplex_step, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;66;03m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;66;03m# likelihood to avoid scale issues, but the averaging is done\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;66;03m# automatically in the base model `fit` method\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loglike\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:983\u001b[0m, in \u001b[0;36mKalmanFilter.loglike\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;124;03mCalculate the loglikelihood associated with the statespace model.\u001b[39;00m\n\u001b[0;32m    969\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;124;03m    The joint loglikelihood.\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    981\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    982\u001b[0m                   MEMORY_CONSERVE \u001b[38;5;241m^\u001b[39m MEMORY_NO_LIKELIHOOD)\n\u001b[1;32m--> 983\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    984\u001b[0m loglikelihood_burn \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloglikelihood_burn\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    985\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglikelihood_burn)\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m&\u001b[39m MEMORY_NO_LIKELIHOOD):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:903\u001b[0m, in \u001b[0;36mKalmanFilter._filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[0;32m    900\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix]\n\u001b[0;32m    902\u001b[0m \u001b[38;5;66;03m# Initialize the state\u001b[39;00m\n\u001b[1;32m--> 903\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplex_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;66;03m# Run the filter\u001b[39;00m\n\u001b[0;32m    906\u001b[0m kfilter()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\representation.py:983\u001b[0m, in \u001b[0;36mRepresentation._initialize_state\u001b[1;34m(self, prefix, complex_step)\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialization\u001b[38;5;241m.\u001b[39minitialized:\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitialization is incomplete.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 983\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statespaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplex_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatespace model not initialized.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_representation.pyx:1373\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._representation.dStatespace.initialize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_representation.pyx:1362\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._representation.dStatespace.initialize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_initialization.pyx:288\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._initialization.dInitialization.initialize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_initialization.pyx:406\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._initialization.dInitialization.initialize_stationary_stationary_cov\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_tools.pyx:1206\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._tools._dsolve_discrete_lyapunov\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: LU decomposition error."
     ]
    }
   ],
   "source": [
    "arma_forecasts = {}\n",
    "\n",
    "for df_name, df in weekly_dfs.items():\n",
    "    print(f'Iterating through {df_name}')\n",
    "    \n",
    "    series = df['OBS_Value']\n",
    "    best_arima_order = (2, 1, 2)\n",
    "\n",
    "    # Store the forecasts for each DataFrame\n",
    "    forecasts = []\n",
    "\n",
    "    # Iterate over the series, retraining the model on the most recent 100 data points and forecasting one step ahead\n",
    "    for end in range(100, len(series)):\n",
    "        if end % 50 == 0:\n",
    "            print(f'{end + 50} data points ran')\n",
    "        train_data = series.iloc[end-100:end]\n",
    "        model = ARIMA(train_data, order=best_arima_order)\n",
    "        model_fit = model.fit()\n",
    "        forecast = model_fit.forecast(steps=1)\n",
    "        forecasts.append(forecast[0])\n",
    "\n",
    "    arma_forecasts[df_name] = pd.DataFrame(forecasts, columns=['Forecast'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c8ff4d-34a0-43c5-b7e3-f0ab226f1ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "c0527442-7cac-4344-89b5-b046a348c07f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating through AU\n",
      "Iterating through CA\n",
      "Iterating through CH\n",
      "Iterating through GB\n",
      "Iterating through JP\n",
      "Iterating through NZ\n",
      "Iterating through XM\n"
     ]
    }
   ],
   "source": [
    "arma_forecasts = {}\n",
    "for df in weekly_dfs:\n",
    "    print(f'Iterating through {df}')\n",
    "    \n",
    "    series = weekly_dfs[df]['OBS_Value']\n",
    "\n",
    "    best_arima_order = (2, 1, 2)\n",
    "\n",
    "    best_model = ARIMA(series, order=best_arima_order)\n",
    "    best_model_fit = best_model.fit()\n",
    "    forecast = best_model_fit.forecast(steps=100)\n",
    "    arma_forecasts[df] = pd.DataFrame(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "edfde89c-15d6-49a8-bc32-ebac2e7b39fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast_diff = {}\n",
    "\n",
    "for key, val in last_update.items():\n",
    "    for key2, val2 in arma_forecasts.items():\n",
    "        if key2 in key:\n",
    "            forecast_diff[key2] = (val - val2) / val\n",
    "        else:\n",
    "            if key == 'EURUSD.a':\n",
    "                if key2 == 'XM':\n",
    "                    forecast_diff[key2] = (val - val2) / val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "16698e66-0e4c-4769-ab30-f6501b566f1e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AU': 2023-12-24    1.044799\n",
       " Freq: W-SUN, dtype: float64,\n",
       " 'CA': 2023-12-24    1.025587\n",
       " Freq: W-SUN, dtype: float64,\n",
       " 'CH': 2023-12-24    0.638441\n",
       " Freq: W-SUN, dtype: float64,\n",
       " 'GB': 2023-12-24    1.130399\n",
       " Freq: W-SUN, dtype: float64,\n",
       " 'JP': 2023-12-24    1.036089\n",
       " Freq: W-SUN, dtype: float64,\n",
       " 'NZ': 2023-12-24    0.859181\n",
       " Freq: W-SUN, dtype: float64,\n",
       " 'XM': 2023-12-24    1.017419\n",
       " Freq: W-SUN, dtype: float64}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c6c915-d94a-468f-982c-ef9d667d266b",
   "metadata": {},
   "source": [
    "### Regression Model / Monte Carlo Sim / weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2dc83aa1-29e2-4362-b212-7f04ae2bbc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6b6948da-6623-4869-94fe-682ffb943562",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------- Testing variable list ['W_EER_ret', 'M_EER_ret'] --------- \n",
      "Looping through AU\n",
      "Coefficient of determination (R^2): 0.507417\n",
      "**Model with ['W_EER_ret', 'M_EER_ret'] performs better. Updating best model.**\n",
      " --------- Testing variable list ['W_EER_ret'] --------- \n",
      "Looping through AU\n",
      "Coefficient of determination (R^2): 0.648780\n",
      "**Model with ['W_EER_ret'] performs better. Updating best model.**\n",
      " --------- Testing variable list ['W_EER_ret', 'M_EER_ret'] --------- \n",
      "Looping through CA\n",
      "Coefficient of determination (R^2): 0.586411\n",
      "**Model with ['W_EER_ret', 'M_EER_ret'] performs better. Updating best model.**\n",
      " --------- Testing variable list ['W_EER_ret'] --------- \n",
      "Looping through CA\n",
      "Coefficient of determination (R^2): 0.655828\n",
      "**Model with ['W_EER_ret'] performs better. Updating best model.**\n",
      " --------- Testing variable list ['W_EER_ret', 'M_EER_ret'] --------- \n",
      "Looping through CH\n",
      "Coefficient of determination (R^2): 0.310929\n",
      "**Model with ['W_EER_ret', 'M_EER_ret'] performs better. Updating best model.**\n",
      " --------- Testing variable list ['W_EER_ret'] --------- \n",
      "Looping through CH\n",
      "Coefficient of determination (R^2): 0.621076\n",
      "**Model with ['W_EER_ret'] performs better. Updating best model.**\n",
      " --------- Testing variable list ['W_EER_ret', 'M_EER_ret'] --------- \n",
      "Looping through GB\n",
      "Coefficient of determination (R^2): 0.397105\n",
      "**Model with ['W_EER_ret', 'M_EER_ret'] performs better. Updating best model.**\n",
      " --------- Testing variable list ['W_EER_ret'] --------- \n",
      "Looping through GB\n",
      "Coefficient of determination (R^2): 0.446211\n",
      "**Model with ['W_EER_ret'] performs better. Updating best model.**\n",
      " --------- Testing variable list ['W_EER_ret', 'M_EER_ret'] --------- \n",
      "Looping through JP\n",
      "Coefficient of determination (R^2): 0.612449\n",
      "**Model with ['W_EER_ret', 'M_EER_ret'] performs better. Updating best model.**\n",
      " --------- Testing variable list ['W_EER_ret'] --------- \n",
      "Looping through JP\n",
      "Coefficient of determination (R^2): 0.527316\n",
      " --------- Testing variable list ['W_EER_ret', 'M_EER_ret'] --------- \n",
      "Looping through NZ\n",
      "Coefficient of determination (R^2): 0.492969\n",
      "**Model with ['W_EER_ret', 'M_EER_ret'] performs better. Updating best model.**\n",
      " --------- Testing variable list ['W_EER_ret'] --------- \n",
      "Looping through NZ\n",
      "Coefficient of determination (R^2): 0.470826\n",
      " --------- Testing variable list ['W_EER_ret', 'M_EER_ret'] --------- \n",
      "Looping through XM\n",
      "Coefficient of determination (R^2): 0.561438\n",
      "**Model with ['W_EER_ret', 'M_EER_ret'] performs better. Updating best model.**\n",
      " --------- Testing variable list ['W_EER_ret'] --------- \n",
      "Looping through XM\n",
      "Coefficient of determination (R^2): 0.597834\n",
      "**Model with ['W_EER_ret'] performs better. Updating best model.**\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "best_model_vars_dict = {}\n",
    "\n",
    "X_vars = [['W_EER_ret', 'M_EER_ret'], ['W_EER_ret']]\n",
    "for df in weekly_dfs:\n",
    "    best_score = float('-inf')  # Initialize the best score as negative infinity\n",
    "    best_model = None  # Initialize the best model\n",
    "    for variables in X_vars:\n",
    "        print(f\" --------- Testing variable list {variables} --------- \")\n",
    "        print(f\"Looping through {df}\")\n",
    "        X = weekly_dfs[df][variables].dropna()\n",
    "        y = weekly_dfs[df]['close_ret'].dropna()\n",
    "        y = y.iloc[-len(X):]\n",
    "\n",
    "        # Splitting the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "        # Creating the linear regression model\n",
    "        model = LinearRegression()\n",
    "        \n",
    "        # Training the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Making predictions using the testing set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # The coefficients\n",
    "        # print('Coefficients:', model.coef_)\n",
    "        # The mean squared error\n",
    "        # print('Mean squared error (MSE): %.6f' % mean_squared_error(y_test, y_pred))\n",
    "        # The coefficient of determination: 1 is perfect prediction\n",
    "        print('Coefficient of determination (R^2): %.6f' % r2_score(y_test, y_pred))\n",
    "        new_score = r2_score(y_test, y_pred)\n",
    "        # Check if this model is better\n",
    "        if new_score > best_score:\n",
    "            print(f\"**Model with {variables} performs better. Updating best model.**\")\n",
    "            best_score = new_score\n",
    "            best_model = model\n",
    "            best_model_vars = variables\n",
    "            \n",
    "    models[df] = best_model\n",
    "    best_model_vars_dict[df] = best_model_vars  # Store the best variables in the dictionary\n",
    "\n",
    "    stats[df] = calc_stats(weekly_dfs[df][best_model_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a2729521-640c-4fe1-aaf5-154580e9d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_returns = pd.DataFrame()\n",
    "for sym in count_codes:\n",
    "    # print(f'Iterating thru {sym}')\n",
    "    rates = get_rates(sym[0], mt5.TIMEFRAME_D1, 2000)\n",
    "    rates = rates['close']\n",
    "    rates = rates.rename(f'{sym[0]}_close')\n",
    "    all_returns = pd.concat([all_returns, rates], axis = 1)\n",
    "latest_prices = all_returns.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "dc96a15c-def6-4d05-9bbd-3adeedf0bd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AU': ['W_EER_ret'],\n",
       " 'CA': ['W_EER_ret'],\n",
       " 'CH': ['W_EER_ret'],\n",
       " 'GB': ['W_EER_ret'],\n",
       " 'JP': ['W_EER_ret', 'M_EER_ret'],\n",
       " 'NZ': ['W_EER_ret', 'M_EER_ret'],\n",
       " 'XM': ['W_EER_ret']}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_vars_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "0a11ab2f-730f-4a94-aae6-b669f6eeb745",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "\n",
    "    if (i + 1) % 250 == 0:\n",
    "        print(f'{i + 1} simulations ran')\n",
    "\n",
    "    expected_return_lst = {}\n",
    "    for df, values in stats.items():\n",
    "        mean = values['mean']\n",
    "        std = values['std']\n",
    "\n",
    "        for df2, lr_model in models.items():\n",
    "            if df == df2:\n",
    "                num_features = len(best_model_vars_dict[df2])  # Number of features the model was trained on\n",
    "                # Ensure mean and std have correct dimensions\n",
    "                mean_values = np.full(num_features, mean)\n",
    "                std_values = np.full(num_features, std)\n",
    "                # Generate random values for each feature\n",
    "                random_eer_ret = np.random.normal(mean_values, std_values, (1, num_features))\n",
    "                # Predict using the model\n",
    "                expected_return_lst[df2] = lr_model.predict(random_eer_ret)\n",
    "            \n",
    "    lst = []\n",
    "    for i in expected_return_lst.values():\n",
    "        lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "eccfff1f-c3d5-408e-a6ea-f4a42535229a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 simulations ran\n",
      "500 simulations ran\n",
      "750 simulations ran\n",
      "1000 simulations ran\n",
      "1250 simulations ran\n",
      "1500 simulations ran\n",
      "1750 simulations ran\n",
      "2000 simulations ran\n",
      "2250 simulations ran\n",
      "2500 simulations ran\n",
      "2750 simulations ran\n",
      "3000 simulations ran\n",
      "3250 simulations ran\n",
      "3500 simulations ran\n",
      "3750 simulations ran\n",
      "4000 simulations ran\n",
      "4250 simulations ran\n",
      "4500 simulations ran\n",
      "4750 simulations ran\n",
      "5000 simulations ran\n",
      "5250 simulations ran\n",
      "5500 simulations ran\n",
      "5750 simulations ran\n",
      "6000 simulations ran\n",
      "6250 simulations ran\n",
      "6500 simulations ran\n",
      "6750 simulations ran\n",
      "7000 simulations ran\n",
      "7250 simulations ran\n",
      "7500 simulations ran\n",
      "7750 simulations ran\n",
      "8000 simulations ran\n",
      "8250 simulations ran\n",
      "8500 simulations ran\n",
      "8750 simulations ran\n",
      "9000 simulations ran\n",
      "9250 simulations ran\n",
      "9500 simulations ran\n",
      "9750 simulations ran\n",
      "10000 simulations ran\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pypfopt import EfficientFrontier, risk_models, expected_returns\n",
    "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices \n",
    "\n",
    "num_simulations = 10000\n",
    "all_weights = []\n",
    "\n",
    "for i in range(num_simulations):\n",
    "\n",
    "    if (i + 1) % 250 == 0:\n",
    "        print(f'{i + 1} simulations ran')\n",
    "\n",
    "    expected_return_lst = {}\n",
    "    for df, values in stats.items():\n",
    "        mean = values['mean']\n",
    "        std = values['std']\n",
    "\n",
    "        for df2, lr_model in models.items():\n",
    "            if df == df2:\n",
    "                num_features = len(best_model_vars_dict[df2])  # Number of features the model was trained on\n",
    "                # Ensure mean and std have correct dimensions\n",
    "                mean_values = np.full(num_features, mean)\n",
    "                std_values = np.full(num_features, std)\n",
    "                # Generate random values for each feature\n",
    "                random_eer_ret = np.random.normal(mean_values, std_values, (1, num_features))\n",
    "                # Predict using the model\n",
    "                expected_return_lst[df2] = lr_model.predict(random_eer_ret)\n",
    "            \n",
    "    lst = []\n",
    "    for i in expected_return_lst.values():\n",
    "        lst.append(i)\n",
    "        \n",
    "    highest_return = max(lst)\n",
    "    desired_scale = 0.05  # 5%\n",
    "    scaling_factor = desired_scale / highest_return\n",
    "    \n",
    "    # Apply the scaling factor\n",
    "    scaled_returns = [ret * scaling_factor for ret in lst] \n",
    "    scaled_values = [x[0] * 100 for x in scaled_returns]\n",
    "    fin = []\n",
    "    for i in scaled_values:\n",
    "        fin.append(abs(i))\n",
    "    \n",
    "    # Calculate expected returns and the covariance matrix\n",
    "    mu = fin\n",
    "    S = risk_models.sample_cov(all_returns)\n",
    "\n",
    "    # Optimize for the minimised volatility\n",
    "    ef = EfficientFrontier(mu, S, weight_bounds = (0.05, 0.25))\n",
    "    weights = ef.efficient_risk(0.025, market_neutral = False)\n",
    "    cleaned_weights = ef.clean_weights()\n",
    "    \n",
    "    exp_ret, exp_vol, sharpe = ef.portfolio_performance()\n",
    "    da = DiscreteAllocation(\n",
    "    cleaned_weights, latest_prices, \n",
    "    total_portfolio_value = 10000, short_ratio = None)\n",
    "    \n",
    "    # Perform the discrete allocation\n",
    "    allocation, leftover = da.lp_portfolio()\n",
    "    # Calculate the total investment in each asset\n",
    "    total_investment = {ticker: allocation[ticker] * latest_prices[ticker] for ticker in allocation}\n",
    "\n",
    "    # Total value of the portfolio\n",
    "    total_portfolio_value = sum(total_investment.values()) + leftover\n",
    "\n",
    "    # Convert to percentages\n",
    "    portfolio_percentages = {ticker: (value / total_portfolio_value) * 100 for ticker, value in total_investment.items()}\n",
    "    \n",
    "    # Store the weights from each simulation\n",
    "    # all_weights[i, :] = np.array(list(portfolio_percentages.values()))\n",
    "    all_weights.append([portfolio_percentages, exp_ret, exp_vol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "a4d51a66-cf65-4d67-ae72-b719634778a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Portfolio Weights:\n",
      "USDCAD.a_close    22.780229\n",
      "USDCHF.a_close    20.829847\n",
      "GBPUSD.a_close     9.302940\n",
      "USDJPY.a_close    13.285449\n",
      "NZDUSD.a_close    13.377707\n",
      "EURUSD.a_close    14.508887\n",
      "AUDUSD.a_close    11.256490\n",
      "dtype: float64\n",
      "\n",
      "Mean Expected Return: 6.648499074651092\n",
      "Mean Expected Volatility: 0.0248788400838889\n"
     ]
    }
   ],
   "source": [
    "weights_list = []\n",
    "returns_list = []\n",
    "volatility_list = []\n",
    "\n",
    "# Extract values into separate lists\n",
    "for item in all_weights:\n",
    "    weights_list.append(item[0])  # Portfolio weights dictionary\n",
    "    returns_list.append(item[1])  # Expected return\n",
    "    volatility_list.append(item[2])  # Expected volatility\n",
    "\n",
    "# Convert weights to DataFrame for easier mean calculation\n",
    "df_weights = pd.DataFrame(weights_list)\n",
    "\n",
    "# Calculate mean weights, returns, and volatility\n",
    "mean_weights = df_weights.mean()\n",
    "mean_return = np.mean(returns_list)\n",
    "mean_volatility = np.mean(volatility_list)\n",
    "\n",
    "print(\"Mean Portfolio Weights:\")\n",
    "print(mean_weights)\n",
    "print(\"\\nMean Expected Return:\", mean_return)\n",
    "print(\"Mean Expected Volatility:\", mean_volatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "f7118440-5863-4179-b0d1-eb75c8430ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "weights_list = []\n",
    "returns_list = []\n",
    "volatility_list = []\n",
    "\n",
    "# Extract values into separate lists\n",
    "for item in all_weights:\n",
    "    weights_list.append(item[0])  # Portfolio weights dictionary\n",
    "    returns_list.append(item[1])  # Expected return\n",
    "    volatility_list.append(item[2])  # Expected volatility\n",
    "\n",
    "# Convert weights to DataFrame for easier mean and IQR calculation\n",
    "df_weights = pd.DataFrame(weights_list)\n",
    "\n",
    "# Calculate mean weights and IQR for each asset\n",
    "mean_weights = df_weights.mean()\n",
    "iqr_weights = df_weights.quantile(0.75) - df_weights.quantile(0.25)\n",
    "iqr_25_weights = df_weights.quantile(0.25)\n",
    "iqr_75_weights = df_weights.quantile(0.75)\n",
    "\n",
    "# Combine return and volatility data\n",
    "df_performance = pd.DataFrame({\n",
    "    'expected_return': returns_list,\n",
    "    'expected_volatility': volatility_list\n",
    "})\n",
    "\n",
    "# Calculate mean return and volatility\n",
    "mean_return = df_performance['expected_return'].mean()\n",
    "iqr_25_ret = df_performance['expected_return'].quantile(0.25)\n",
    "iqr_75_ret = df_performance['expected_return'].quantile(0.75)\n",
    "\n",
    "mean_volatility = df_performance['expected_volatility'].mean()\n",
    "iqr_25_vol = df_performance['expected_volatility'].quantile(0.25)\n",
    "iqr_75_vol = df_performance['expected_volatility'].quantile(0.75)\n",
    "\n",
    "iqr_25_dict = {}\n",
    "iqr_75_dict = {}\n",
    "mean_dict = {}\n",
    "\n",
    "for index, row in df_weights.iterrows():\n",
    "    row_sum = row.sum()\n",
    "    shortfall = 100 - row_sum\n",
    "    null_columns = row[row.isnull()].index  # Identify columns with NaN values\n",
    "    df_weights.loc[index, null_columns] = shortfall / len(null_columns)  # Distribute the shortfall evenly\n",
    "\n",
    "    # Convert weights to a tuple for hashability\n",
    "    # tuple_weights = tuple(row.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "c9a6a9ec-e0cb-4a05-a1d2-1484af6200b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df = pd.DataFrame(returns_list)\n",
    "lower_threshold = [x for x in returns_df[0] if x < 2.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "7cdb900c-b0d2-4513-92f3-d8459ce6b0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lower_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "7d9f4fed-f043-4eea-a426-d5e32aca01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr_25_dict['weights'] = iqr_25_weights\n",
    "iqr_75_dict['weights'] = iqr_75_weights\n",
    "mean_dict['weights'] = mean_weights\n",
    "\n",
    "iqr_25_dict['ret'] = iqr_25_ret\n",
    "iqr_75_dict['ret'] = iqr_75_ret\n",
    "mean_dict['ret'] = mean_return\n",
    "\n",
    "iqr_25_dict['vol'] = iqr_25_vol\n",
    "iqr_75_dict['vol'] = iqr_75_vol\n",
    "mean_dict['vol'] = mean_volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "1be4d076-b7b1-434c-81f1-fbd86abd0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "all_dicts = {}\n",
    "\n",
    "all_dicts['iqr25'] = iqr_25_dict\n",
    "all_dicts['iqr75'] = iqr_75_dict\n",
    "all_dicts['mean_dict'] = mean_dict\n",
    "\n",
    "for df, items in all_dicts.items():\n",
    "    highest_ret = 0\n",
    "    if all_dicts[df]['ret'] > highest_ret:\n",
    "        highest_ret = all_dicts[df]['ret']\n",
    "        weights = all_dicts[df]['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "bb8deed4-a6a2-4098-ad0c-f8af46170490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_weights(weights):\n",
    "\n",
    "    total_weights = __builtins__.sum(weights.values)\n",
    "    scaled = {currency: weight / total_weights * 100 for currency, weight in weights.items()}\n",
    "\n",
    "    if isinstance(weights, pd.Series):\n",
    "        return pd.Series(scaled)\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "ca2a90bc-cbff-48b5-b1cf-b78b55dd68d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = scale_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfea177-5c41-47c9-b167-8a84cda9fe59",
   "metadata": {
    "tags": []
   },
   "source": [
    "### scrap code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "ebb4c260-2410-4769-bb02-f09f23f430e6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match found for AU and AU\n",
      "[0.00976244]\n",
      "match found for CA and CA\n",
      "[-0.01374206]\n",
      "match found for CH and CH\n",
      "[0.00070739]\n",
      "match found for GB and GB\n",
      "[0.00295269]\n",
      "match found for JP and JP\n",
      "[-0.00557417]\n",
      "match found for NZ and NZ\n",
      "[-0.0166149]\n",
      "match found for XM and XM\n",
      "[0.00791541]\n"
     ]
    }
   ],
   "source": [
    "expected_return_lst = {}\n",
    "for df, values in stats.items():\n",
    "    mean = values['mean']\n",
    "    std = values['std']\n",
    "    \n",
    "    for df2, lr_model in models.items():\n",
    "        if df == df2:\n",
    "            print(f'match found for {df} and {df2}')\n",
    "            # Regression Model calculating expected returns \n",
    "            # expected_return_lst = {}\n",
    "            random_eer_ret = np.random.normal(mean, std, 1).reshape(-1,1)\n",
    "            print(lr_model.predict(random_eer_ret))\n",
    "            expected_return_lst[df2] = lr_model.predict(random_eer_ret)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "e6247f6a-4f48-4fa9-a63c-20c2e3f48b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in expected_return_lst.values():\n",
    "    lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "da39ae1e-373b-4267-a184-ca9627da17d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "highest_return = max(lst)\n",
    "desired_scale = 0.05  # 5%\n",
    "scaling_factor = desired_scale / highest_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "d4e7b3f8-5469-4abb-b3b7-e1ae5b7573d3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.05]),\n",
       " array([-0.07038234]),\n",
       " array([0.00362304]),\n",
       " array([0.01512269]),\n",
       " array([-0.02854906]),\n",
       " array([-0.08509608]),\n",
       " array([0.04054015])]"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the scaling factor\n",
    "scaled_returns = [ret * scaling_factor for ret in lst] \n",
    "scaled_returns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "dfe234d4-5ec2-4011-97f2-00eb89dd5448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaled_values = [x[0] * 100 for x in scaled_returns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "2c9ce4e3-8b65-45ec-b608-6dd2e53b36f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fin = []\n",
    "for i in scaled_values:\n",
    "    fin.append(abs(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "27ea660e-4e0f-4c4d-b1ed-72f00fad4807",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('AUDUSD.a_close', 0.05), ('USDCAD.a_close', 0.25), ('USDCHF.a_close', 0.12749), ('GBPUSD.a_close', 0.05), ('USDJPY.a_close', 0.14772), ('NZDUSD.a_close', 0.2432), ('EURUSD.a_close', 0.13159)])\n"
     ]
    }
   ],
   "source": [
    "from pypfopt import EfficientFrontier, risk_models, expected_returns\n",
    "\n",
    "# Assuming 'data' is your DataFrame with historical returns\n",
    "# Calculate expected returns and the covariance matrix\n",
    "mu = fin\n",
    "S = risk_models.sample_cov(all_returns)\n",
    "\n",
    "# Optimize for the minimised volatility\n",
    "ef = EfficientFrontier(mu, S, weight_bounds = (0.05, 0.25))\n",
    "weights = ef.efficient_risk(0.025, market_neutral = False)\n",
    "cleaned_weights = ef.clean_weights()\n",
    "print(cleaned_weights)\n",
    "\n",
    "# Performance metrics\n",
    "expected_return, expected_volatility, expected_sharpe = ef.portfolio_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "4c051b21-8299-4e27-a55c-4ac728a9a6ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "da = discrete_allocation.DiscreteAllocation(\n",
    "    cleaned_weights, latest_prices, \n",
    "    total_portfolio_value = 10000, short_ratio = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "fb44d758-62dc-4bcc-a37c-adcc3fa0a45c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform the discrete allocation\n",
    "allocation, leftover = da.lp_portfolio()\n",
    "# Calculate the total investment in each asset\n",
    "total_investment = {ticker: allocation[ticker] * latest_prices[ticker] for ticker in allocation}\n",
    "\n",
    "# Total value of the portfolio\n",
    "total_portfolio_value = sum(total_investment.values()) + leftover\n",
    "\n",
    "# Convert to percentages\n",
    "portfolio_percentages = {ticker: (value / total_portfolio_value) * 100 for ticker, value in total_investment.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc713cf-7bbd-48e9-9bd5-5cbb05d0e8d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_simulations = 1000\n",
    "all_weights = np.zeros((num_simulations, len(data.columns)))\n",
    "\n",
    "for i in range(num_simulations):\n",
    "    # Simulate the returns - this is a simple simulation; adjust as needed\n",
    "    simulated_returns = np.random.normal(mu, S, size=(len(data), len(data.columns)))\n",
    "    \n",
    "    # Re-run MVO for the simulated returns\n",
    "    ef = EfficientFrontier(simulated_returns.mean(axis=0), risk_models.sample_cov(pd.DataFrame(simulated_returns)))\n",
    "    weights = ef.max_sharpe()\n",
    "    cleaned_weights = ef.clean_weights()\n",
    "    \n",
    "    # Store the weights from each simulation\n",
    "    all_weights[i, :] = np.array(list(cleaned_weights.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df9309e-939a-4662-9fe2-7f449f8b5bd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Orders \n",
    "- Create a class that takes in ALL orders before sending through so you can run a monte carlo simulation of portfolio of total portfolio to get the expected std's etc. Adjust as needed with a final MVO. Target STD/Volatility for each week is 2.5% \n",
    "Monte carlo simulation of all orders going through"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08363705-6415-4b47-939e-6c41ba48a0b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simple Order Send\n",
    "Copying EER return direction as data is released."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72dd01c3-f32e-4ab1-a6d2-97628b667bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = []\n",
    "for sym in count_codes:\n",
    "    symbols.append(sym[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76805392-b9ed-4e10-8ed0-e9d6db03b55c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combinations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m all_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mcombinations\u001b[49m(symbols, \u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combinations' is not defined"
     ]
    }
   ],
   "source": [
    "all_pairs = list(combinations(symbols, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b84f8-f7c5-4c8e-92f2-24bd4786d935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7fb71b-51fc-4644-a14e-ba1a07ef1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(series1, series2):\n",
    "    '''Runs ADF test on a spread series'''\n",
    "    spread = series1 - series2\n",
    "    result = adfuller(spread)\n",
    "    return {'ADF Statistic': result[0], 'p-value': result[1], 'Critical Values': result[4]}\n",
    "\n",
    "for sym in all_pairs:\n",
    "    series1 = get_rates(sym[0], mt5.TIMEFRAME_D1, 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83d105d2-18be-474e-a430-a1fb22ae1d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_send():\n",
    "    for symbol, value in last_update.items():\n",
    "        if symbol[:3] == 'USD':\n",
    "            print(f\"Looping through {symbol}\")\n",
    "            if value > 0:\n",
    "                send_order(symbol, 'sell', 1.00, 'EER')\n",
    "                print(f\"Selling {symbol}\")\n",
    "            else:\n",
    "                send_order(symbol, 'buy', 1.00, 'EER')\n",
    "        else:\n",
    "            if value > 0:\n",
    "                send_order(symbol, 'buy', 1.00, 'EER')\n",
    "            else:\n",
    "                send_order(symbol, 'sell', 1.00, 'EER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "11950bf2-a069-4eb8-b954-2dcfe630cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_weights_send():\n",
    "    for symbol, value in last_update.items():\n",
    "        print(f\"Looping through {symbol}\")\n",
    "\n",
    "        # Find the corresponding weight for the symbol\n",
    "        for sym, weight in weights.items():\n",
    "            if symbol[:7] == sym[:7]:  # Assuming symbol format like 'AUDUSD.a'\n",
    "                lotsize = weight\n",
    "                break\n",
    "        else:\n",
    "            continue  # If no matching weight is found, continue to next symbol\n",
    "\n",
    "        # Determine whether to buy or sell based on the value\n",
    "        lotsize = round(( weight / 7 ), 2)\n",
    "        \n",
    "        if symbol[:3] == 'USD':\n",
    "            print(f\"Looping through {symbol}\")\n",
    "            if value > 0:\n",
    "                send_order(symbol, 'sell', lotsize, 'MC_EER')\n",
    "                print(f\"Selling {symbol}\")\n",
    "            else:\n",
    "                send_order(symbol, 'buy', lotsize, 'MC_EER')\n",
    "        else:\n",
    "            if value > 0:\n",
    "                send_order(symbol, 'buy', lotsize, 'MC_EER')\n",
    "            else:\n",
    "                send_order(symbol, 'sell', lotsize, 'MC_EER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "5fd9b5f0-e65b-4fc2-a521-90ccf9afb45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looping through AUDUSD.a\n",
      "Looping through USDCAD.a\n",
      "Looping through USDCAD.a\n",
      "Selling USDCAD.a\n",
      "Looping through USDCHF.a\n",
      "Looping through USDCHF.a\n",
      "Looping through GBPUSD.a\n",
      "Looping through USDJPY.a\n",
      "Looping through USDJPY.a\n",
      "Selling USDJPY.a\n",
      "Looping through NZDUSD.a\n",
      "Looping through EURUSD.a\n"
     ]
    }
   ],
   "source": [
    "mc_weights_send()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf4f6b-eba9-478a-b23f-016d21a13558",
   "metadata": {},
   "source": [
    "### Pair / Triplet Trading\n",
    "\n",
    "Trading based on a cointegrating relationship within EER values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc835c3-f4af-42ef-9fa1-36c84163c154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c8bf2de-9fa1-446f-b020-8ef485387509",
   "metadata": {},
   "source": [
    "### Mean Reversion / Momentum \n",
    "\n",
    "Based on mean-reverting nature of EER values balanced with the momentum of EER values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc150523-71df-4c39-b270-e3982ad21bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39eade-e286-4afa-987a-08df4a1fa665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421737b-d82e-469f-a088-b08958293d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7193a304-0971-479f-a0bf-a5fcf51a7646",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Research\n",
    "\n",
    "Analyzing the relationship of EER data and close prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "7482aabc-60fb-4206-9c25-0ffbe54a44db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in weekly_dfs.values():\n",
    "    df['ret'] = df['close'].pct_change()\n",
    "    df['ret_diff'] = df['EER_ret'] - df['ret']\n",
    "    df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "c2103158-3c2e-4ed0-97d7-3d55b56a1cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER Correlation with AU is: 0.7895590513032674\n",
      "EER Correlation with CA is: -0.8034449420507715\n",
      "EER Correlation with CH is: -0.6962195656612519\n",
      "EER Correlation with GB is: 0.6871875814155363\n",
      "EER Correlation with JP is: -0.8164550108813893\n",
      "EER Correlation with NZ is: 0.774779037008523\n",
      "EER Correlation with XM is: 0.7549860097389316\n"
     ]
    }
   ],
   "source": [
    "for name, df in weekly_dfs.items():\n",
    "    print(f\"EER Correlation with {name} is: {df['EER_ret'].corr(df['ret'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "72aa1e6e-873f-4fc9-af82-5c6075060ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AU Stats</th>\n",
       "      <th>CA Stats</th>\n",
       "      <th>CH Stats</th>\n",
       "      <th>GB Stats</th>\n",
       "      <th>JP Stats</th>\n",
       "      <th>NZ Stats</th>\n",
       "      <th>XM Stats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>499.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>-0.001096</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.009047</td>\n",
       "      <td>0.018505</td>\n",
       "      <td>0.020930</td>\n",
       "      <td>0.009593</td>\n",
       "      <td>0.022437</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>0.007556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.053037</td>\n",
       "      <td>-0.064334</td>\n",
       "      <td>-0.104875</td>\n",
       "      <td>-0.050289</td>\n",
       "      <td>-0.100707</td>\n",
       "      <td>-0.055615</td>\n",
       "      <td>-0.033891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.005061</td>\n",
       "      <td>-0.011256</td>\n",
       "      <td>-0.009507</td>\n",
       "      <td>-0.005547</td>\n",
       "      <td>-0.013601</td>\n",
       "      <td>-0.005001</td>\n",
       "      <td>-0.004506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000292</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>-0.000457</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>-0.002314</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.011485</td>\n",
       "      <td>0.009052</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>0.005819</td>\n",
       "      <td>0.004759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.033373</td>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.284139</td>\n",
       "      <td>0.036804</td>\n",
       "      <td>0.077664</td>\n",
       "      <td>0.039223</td>\n",
       "      <td>0.029442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AU Stats    CA Stats    CH Stats    GB Stats    JP Stats    NZ Stats  \\\n",
       "count  499.000000  499.000000  499.000000  499.000000  499.000000  499.000000   \n",
       "mean     0.000299   -0.000728    0.000471    0.000336   -0.001096    0.000350   \n",
       "std      0.009047    0.018505    0.020930    0.009593    0.022437    0.009860   \n",
       "min     -0.053037   -0.064334   -0.104875   -0.050289   -0.100707   -0.055615   \n",
       "25%     -0.005061   -0.011256   -0.009507   -0.005547   -0.013601   -0.005001   \n",
       "50%      0.000292   -0.000322   -0.000457    0.000599   -0.002314    0.000192   \n",
       "75%      0.005601    0.011485    0.009052    0.005842    0.011016    0.005819   \n",
       "max      0.033373    0.059054    0.284139    0.036804    0.077664    0.039223   \n",
       "\n",
       "         XM Stats  \n",
       "count  499.000000  \n",
       "mean     0.000288  \n",
       "std      0.007556  \n",
       "min     -0.033891  \n",
       "25%     -0.004506  \n",
       "50%      0.000589  \n",
       "75%      0.004759  \n",
       "max      0.029442  "
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_stats = pd.DataFrame()\n",
    "\n",
    "for name in weekly_dfs:\n",
    "    desc_stats[f\"{name} Stats\"] = weekly_dfs[name]['ret_diff'].describe()\n",
    "desc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "6aab6ab2-fcb7-42df-80b9-d5f34600ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "eer_vals = pd.DataFrame()\n",
    "\n",
    "for name in weekly_dfs:\n",
    "    eer_vals[f'{name}'] = weekly_dfs[name]['OBS_Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "14678f4e-3b14-4797-bfde-22bff26f553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import coint\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller \n",
    "\n",
    "def cointegration_test(series1, series2):\n",
    "    '''Runs cointegration test on two series'''\n",
    "    score, p_value, _ = coint(series1, series2)\n",
    "    return {'Cointegration Score': score, 'p-value': p_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "93d8a545-0c83-4c98-a72c-862d3806cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = list(combinations(eer_vals.columns, 2))\n",
    "all_trips = list(combinations(eer_vals.columns, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "b9c0298f-9818-47da-ad99-c915c1ee127d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adf_test(series1, series2):\n",
    "    '''Runs ADF test on a spread series'''\n",
    "    spread = series1 - series2\n",
    "    result = adfuller(spread)\n",
    "    return {'ADF Statistic': result[0], 'p-value': result[1], 'Critical Values': result[4]}\n",
    "\n",
    "def johansen_test(data, det_order=0, k_ar_diff=1):\n",
    "\n",
    "    result = coint_johansen(data, det_order, k_ar_diff)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "0b8caac4-7782-4ecb-b3f6-46d026c0ab4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('AU', 'NZ'): {'ADF_Stat': -4.1478, '10%_stat': -2.5699},\n",
       " ('CA', 'NZ'): {'ADF_Stat': -4.1739, '10%_stat': -2.5699},\n",
       " ('CA', 'XM'): {'ADF_Stat': -2.6991, '10%_stat': -2.5699},\n",
       " ('NZ', 'XM'): {'ADF_Stat': -2.571, '10%_stat': -2.5699}}"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform cointegration test on each pair\n",
    "coint_results = {}\n",
    "for pair in all_pairs:\n",
    "    series1, series2 = eer_vals[pair[0]], eer_vals[pair[1]]\n",
    "    coint_test_result = adf_test(series1, series2)\n",
    "    if coint_test_result['Critical Values']['10%'] > coint_test_result['ADF Statistic']:\n",
    "        # print(f\"{coint_test_result['Critical Values']['10%']} is smaller than {coint_test_result['ADF Statistic']}. Adding to results\")\n",
    "        coint_results[pair] = {'ADF_Stat': round(coint_test_result['ADF Statistic'], 4), \n",
    "                               '10%_stat': round(coint_test_result['Critical Values']['10%'], 4)}\n",
    "coint_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "a0b16314-6d48-4c20-af01-b579e21fc870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AU</th>\n",
       "      <th>CA</th>\n",
       "      <th>CH</th>\n",
       "      <th>GB</th>\n",
       "      <th>JP</th>\n",
       "      <th>NZ</th>\n",
       "      <th>XM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-05-25</th>\n",
       "      <td>119.55</td>\n",
       "      <td>118.63</td>\n",
       "      <td>90.36</td>\n",
       "      <td>114.02</td>\n",
       "      <td>95.19</td>\n",
       "      <td>113.35</td>\n",
       "      <td>105.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-01</th>\n",
       "      <td>120.61</td>\n",
       "      <td>119.35</td>\n",
       "      <td>90.36</td>\n",
       "      <td>113.41</td>\n",
       "      <td>95.38</td>\n",
       "      <td>112.25</td>\n",
       "      <td>105.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-08</th>\n",
       "      <td>121.06</td>\n",
       "      <td>118.37</td>\n",
       "      <td>90.58</td>\n",
       "      <td>113.84</td>\n",
       "      <td>94.61</td>\n",
       "      <td>112.78</td>\n",
       "      <td>105.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-15</th>\n",
       "      <td>121.81</td>\n",
       "      <td>119.26</td>\n",
       "      <td>90.29</td>\n",
       "      <td>115.36</td>\n",
       "      <td>95.10</td>\n",
       "      <td>114.50</td>\n",
       "      <td>104.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-22</th>\n",
       "      <td>121.76</td>\n",
       "      <td>119.58</td>\n",
       "      <td>90.48</td>\n",
       "      <td>115.60</td>\n",
       "      <td>94.96</td>\n",
       "      <td>114.89</td>\n",
       "      <td>105.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-19</th>\n",
       "      <td>101.76</td>\n",
       "      <td>100.03</td>\n",
       "      <td>111.49</td>\n",
       "      <td>102.15</td>\n",
       "      <td>73.96</td>\n",
       "      <td>99.72</td>\n",
       "      <td>100.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-26</th>\n",
       "      <td>102.54</td>\n",
       "      <td>100.19</td>\n",
       "      <td>111.62</td>\n",
       "      <td>102.95</td>\n",
       "      <td>73.69</td>\n",
       "      <td>100.72</td>\n",
       "      <td>100.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-03</th>\n",
       "      <td>103.02</td>\n",
       "      <td>101.12</td>\n",
       "      <td>112.62</td>\n",
       "      <td>103.62</td>\n",
       "      <td>74.34</td>\n",
       "      <td>102.05</td>\n",
       "      <td>99.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-10</th>\n",
       "      <td>102.83</td>\n",
       "      <td>100.99</td>\n",
       "      <td>113.26</td>\n",
       "      <td>103.62</td>\n",
       "      <td>76.60</td>\n",
       "      <td>101.70</td>\n",
       "      <td>98.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-17</th>\n",
       "      <td>103.38</td>\n",
       "      <td>102.03</td>\n",
       "      <td>113.01</td>\n",
       "      <td>103.74</td>\n",
       "      <td>77.36</td>\n",
       "      <td>101.57</td>\n",
       "      <td>99.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AU      CA      CH      GB     JP      NZ      XM\n",
       "date                                                             \n",
       "2014-05-25  119.55  118.63   90.36  114.02  95.19  113.35  105.64\n",
       "2014-06-01  120.61  119.35   90.36  113.41  95.38  112.25  105.57\n",
       "2014-06-08  121.06  118.37   90.58  113.84  94.61  112.78  105.71\n",
       "2014-06-15  121.81  119.26   90.29  115.36  95.10  114.50  104.76\n",
       "2014-06-22  121.76  119.58   90.48  115.60  94.96  114.89  105.11\n",
       "...            ...     ...     ...     ...    ...     ...     ...\n",
       "2023-11-19  101.76  100.03  111.49  102.15  73.96   99.72  100.55\n",
       "2023-11-26  102.54  100.19  111.62  102.95  73.69  100.72  100.65\n",
       "2023-12-03  103.02  101.12  112.62  103.62  74.34  102.05   99.92\n",
       "2023-12-10  102.83  100.99  113.26  103.62  76.60  101.70   98.94\n",
       "2023-12-17  103.38  102.03  113.01  103.74  77.36  101.57   99.53\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eer_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ee1494ba-a429-4c15-b14f-077ec3c083fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  At 90%: 27.0669, Trace Stat = 26.334654627092632\n",
      "  At 95%: 29.7961, Trace Stat = 26.334654627092632\n",
      "  At 99%: 35.4628, Trace Stat = 26.334654627092632\n",
      "  At 90%: 13.4294, Trace Stat = 7.676091331107257\n",
      "  At 95%: 15.4943, Trace Stat = 7.676091331107257\n",
      "  At 99%: 19.9349, Trace Stat = 7.676091331107257\n",
      "  At 90%: 2.7055, Trace Stat = 0.7471535183749242\n",
      "  At 95%: 3.8415, Trace Stat = 0.7471535183749242\n",
      "  At 99%: 6.6349, Trace Stat = 0.7471535183749242\n"
     ]
    }
   ],
   "source": [
    "for sym in all_trips:\n",
    "    data = eer_vals[sym[0]], eer_vals[sym[1]], eer_vals[sym[2]]\n",
    "test_result = johansen_test(pd.DataFrame(data).T)\n",
    "n = len(data)\n",
    "for i in range(n):\n",
    "    print(f\"  At 90%: {test_result.trace_stat_crit_vals[i, 0]}, Trace Stat = {test_result.trace_stat[i]}\")\n",
    "    print(f\"  At 95%: {test_result.trace_stat_crit_vals[i, 1]}, Trace Stat = {test_result.trace_stat[i]}\")\n",
    "    print(f\"  At 99%: {test_result.trace_stat_crit_vals[i, 2]}, Trace Stat = {test_result.trace_stat[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d191e523-36a6-46a3-a0fe-99d48a7b08b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 13.4294 < 13.937368787819146\n",
      "('AU', 'CA', 'GB') cointegrates on a trip. level\n",
      "Result: 13.4294 < 19.290192302491445\n",
      "('AU', 'CA', 'NZ') cointegrates on a trip. level\n",
      "Result: 13.4294 < 17.71064339528753\n",
      "('AU', 'CA', 'XM') cointegrates on a trip. level\n",
      "Result: 13.4294 < 13.440846845315779\n",
      "('AU', 'GB', 'XM') cointegrates on a trip. level\n",
      "Result: 13.4294 < 18.203896258830596\n",
      "('AU', 'NZ', 'XM') cointegrates on a trip. level\n",
      "Result: 13.4294 < 15.570874597943478\n",
      "('CA', 'CH', 'JP') cointegrates on a trip. level\n",
      "Result: 13.4294 < 16.647381123213624\n",
      "('CA', 'GB', 'NZ') cointegrates on a trip. level\n",
      "Result: 13.4294 < 16.29832999361456\n",
      "('CA', 'GB', 'XM') cointegrates on a trip. level\n",
      "Result: 13.4294 < 23.233955281631843\n",
      "('CA', 'NZ', 'XM') cointegrates on a trip. level\n",
      "Result: 13.4294 < 14.135697301903793\n",
      "('GB', 'NZ', 'XM') cointegrates on a trip. level\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "trip_coint_res = {}\n",
    "for sym in all_trips:\n",
    "    data = eer_vals[sym[0]], eer_vals[sym[1]], eer_vals[sym[2]]\n",
    "    test_result = johansen_test(pd.DataFrame(data).T)\n",
    "    \n",
    "    if test_result.trace_stat_crit_vals[1,0] < test_result.trace_stat[1]:\n",
    "        print(f\"Result: {test_result.trace_stat_crit_vals[1,0]} < {test_result.trace_stat[1]}\")\n",
    "        print(f\"{sym} cointegrates on a trip. level\")\n",
    "    \n",
    "    # result = johansen_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f50b88c8-a1b4-4100-8647-6fc67350fd87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AU', 'CA', 'NZ') has 3 cointegrating relationship(s).\n",
      "('AU', 'CA', 'XM') has 3 cointegrating relationship(s).\n",
      "('AU', 'NZ', 'XM') has 3 cointegrating relationship(s).\n",
      "('CA', 'GB', 'NZ') has 3 cointegrating relationship(s).\n",
      "('CA', 'GB', 'XM') has 3 cointegrating relationship(s).\n",
      "('CA', 'NZ', 'XM') has 3 cointegrating relationship(s).\n"
     ]
    }
   ],
   "source": [
    "trip_coint_res = {}\n",
    "for sym in all_trips:\n",
    "    data = pd.DataFrame({sym[0]: eer_vals[sym[0]], sym[1]: eer_vals[sym[1]], sym[2]: eer_vals[sym[2]]})\n",
    "    test_result = johansen_test(data)\n",
    "    \n",
    "    \n",
    "    cointegrating_relations = sum(test_result.trace_stat > test_result.trace_stat_crit_vals[:, 1])\n",
    "    if cointegrating_relations >= 3:\n",
    "        trip_coint_res[sym] = cointegrating_relations\n",
    "\n",
    "    # print(f\"{sym} shows evidence of {cointegrating_relations} cointegrating relationship(s).\")\n",
    "\n",
    "# Output results\n",
    "for trip, relations in trip_coint_res.items():\n",
    "    print(f\"{trip} has {relations} cointegrating relationship(s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "075b9ec6-835e-48e6-a2ee-3202f1e4dedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AU</th>\n",
       "      <th>CA</th>\n",
       "      <th>NZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>501.000000</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>501.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>106.988363</td>\n",
       "      <td>104.074631</td>\n",
       "      <td>104.420279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.515604</td>\n",
       "      <td>4.818668</td>\n",
       "      <td>4.175869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>89.110000</td>\n",
       "      <td>93.230000</td>\n",
       "      <td>95.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>103.110000</td>\n",
       "      <td>101.220000</td>\n",
       "      <td>101.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>106.460000</td>\n",
       "      <td>102.940000</td>\n",
       "      <td>103.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>110.230000</td>\n",
       "      <td>105.950000</td>\n",
       "      <td>106.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>124.420000</td>\n",
       "      <td>121.550000</td>\n",
       "      <td>116.580000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AU          CA          NZ\n",
       "count  501.000000  501.000000  501.000000\n",
       "mean   106.988363  104.074631  104.420279\n",
       "std      5.515604    4.818668    4.175869\n",
       "min     89.110000   93.230000   95.260000\n",
       "25%    103.110000  101.220000  101.550000\n",
       "50%    106.460000  102.940000  103.740000\n",
       "75%    110.230000  105.950000  106.510000\n",
       "max    124.420000  121.550000  116.580000"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eer_vals[['AU', 'CA', 'NZ']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03255baa-d462-4b52-a46a-eea9f91be978",
   "metadata": {},
   "source": [
    "## Risk Management Framework\n",
    "\n",
    "Aim is to take into account associated statistics between the two and minimise volatility whilst maximising return. Appropriate measures can include:\n",
    "- MVO or BL Portfolio\n",
    "- Correlation analysis and appropriate hedging associated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592762c4-897e-4fb4-a459-eef7e0cf2a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7f2f0-8a31-44bd-83a4-662508bdd25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
