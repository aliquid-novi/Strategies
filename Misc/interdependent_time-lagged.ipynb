{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa8ce075-9ace-40cf-abac-70a36f932a2a",
   "metadata": {},
   "source": [
    "Types of methods to be used:\n",
    "1. Cross-Correlation Analysis\n",
    "2. Granger Causality Test\n",
    "3. VAR Model\n",
    "4. Impulse Response Analysis\n",
    "5. Lagged Regression Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a52e893-d01c-4d1c-82e7-a48e895fe67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt5\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "mt5.initialize()\n",
    "account=51127988\n",
    "password=\"Aar2frM7\"\n",
    "server = 'ICMarkets-Demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd296808-b11e-4803-878e-5f57865d4130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rates(pair1, tf, x):\n",
    "    pair1 = pd.DataFrame(mt5.copy_rates_from_pos(pair1, tf, 0, x))\n",
    "    pair1['time'] = pd.to_datetime(pair1['time'], unit = 's')\n",
    "    pair1 = pair1.set_index(pair1['time'])\n",
    "    pair1 = pair1.drop(columns = ['time','tick_volume', 'spread', 'real_volume'])\n",
    "    return pair1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b31e339-cbe0-4501-bc73-e4b402419d61",
   "metadata": {},
   "source": [
    "# Timezones for MT5 (GMT + 3)\n",
    "\n",
    "## SYD - 21:00 TO 06:00\n",
    "## TKO - 11:00 TO 09:00\n",
    "## LDN - 08:00 TO 16:00\n",
    "## NY - 13:00 TO 21:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a78e6e7-6882-434f-893a-3dd5fb5b2d35",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hypothesis \n",
    "\n",
    "The movements of the EURUSD and GBPUSD exchange rates can be used to predict the future direction of the USDJPY exchange rate. Specifically, if both EURUSD and GBPUSD experience an increase within a given time period (e.g., within one hour), there is a statistically significant probability that the USDJPY exchange rate will decrease in the subsequent time period.\n",
    "\n",
    "## Method\n",
    "\n",
    "Gather hourly data of EURUSD and GBPUD. Process the data so that the remaining data are EURUSD and GBPUSD candles that are correlated and have moved more than 10 pips.\n",
    "\n",
    "Gather USDJPY hourly candles for each time period succeeding the new data points gathered.\n",
    "\n",
    "Run a Pearson correlation analysis between the EURUSD-GBPUSD amended data and USDJPY data.\n",
    "\n",
    "## Result \n",
    "\n",
    "No Correlations found \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fb3a4fb-b88c-46ba-b369-5ca1bfc3b223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EU</th>\n",
       "      <th>GU</th>\n",
       "      <th>Spread</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-27 09:00:00</th>\n",
       "      <td>13.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27 10:00:00</th>\n",
       "      <td>-17.4</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>-6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28 17:00:00</th>\n",
       "      <td>-11.2</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29 03:00:00</th>\n",
       "      <td>-10.1</td>\n",
       "      <td>-11.7</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29 13:00:00</th>\n",
       "      <td>17.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-28 12:00:00</th>\n",
       "      <td>13.9</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-28 13:00:00</th>\n",
       "      <td>20.0</td>\n",
       "      <td>34.4</td>\n",
       "      <td>-14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-28 14:00:00</th>\n",
       "      <td>15.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-28 17:00:00</th>\n",
       "      <td>18.7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 10:00:00</th>\n",
       "      <td>-15.1</td>\n",
       "      <td>-13.1</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2089 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       EU    GU  Spread\n",
       "time                                   \n",
       "2021-12-27 09:00:00  13.1  11.0     2.1\n",
       "2021-12-27 10:00:00 -17.4 -11.1    -6.3\n",
       "2021-12-28 17:00:00 -11.2 -22.0    10.8\n",
       "2021-12-29 03:00:00 -10.1 -11.7     1.6\n",
       "2021-12-29 13:00:00  17.3  13.5     3.8\n",
       "...                   ...   ...     ...\n",
       "2023-07-28 12:00:00  13.9  13.4     0.5\n",
       "2023-07-28 13:00:00  20.0  34.4   -14.4\n",
       "2023-07-28 14:00:00  15.8  17.0    -1.2\n",
       "2023-07-28 17:00:00  18.7  11.0     7.7\n",
       "2023-08-01 10:00:00 -15.1 -13.1    -2.0\n",
       "\n",
       "[2089 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EU = get_rates('EURUSD.a', mt5.TIMEFRAME_H1, 10000)\n",
    "GU = get_rates('GBPUSD.a', mt5.TIMEFRAME_H1, 10000)\n",
    "EU_returns = pd.DataFrame(10000 * (EU['close'] - EU['open']))\n",
    "EU_returns.rename(columns = {0:'EU'}, inplace = True)\n",
    "GU_returns = pd.DataFrame(10000 * (GU['close'] - GU['open']))\n",
    "GU_returns.rename(columns = {0:'GU'}, inplace = True)\n",
    "\n",
    "# GU_returns.rename('GU', inplace = True)\n",
    "EU_returns = EU_returns[abs(EU_returns) > 10]\n",
    "GU_returns = GU_returns[abs(GU_returns) > 10]\n",
    "\n",
    "EU_GU = pd.concat([EU_returns, GU_returns], axis = 1)\n",
    "EU_GU = EU_GU.dropna()\n",
    "EU_GU = EU_GU.rename(columns={0: 'EURUSD', 0: 'GBPUSD'})\n",
    "EU_GU[\"Spread\"] = EU_GU['EU'] - EU_GU['GU']\n",
    "EU_GU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962a018c-f68b-4ec2-b2b9-3b64859e9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UJ = get_rates('USDJPY.a', mt5.TIMEFRAME_H1, 10000)\n",
    "UJ_returns = pd.DataFrame(UJ['close'] - UJ['open'])\n",
    "UJ_returns.rename(columns = {0:'UJ'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d56700-9192-40fe-985f-ea4d54a11402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UJ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-27 09:00:00</th>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27 10:00:00</th>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28 17:00:00</th>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29 03:00:00</th>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29 13:00:00</th>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-28 12:00:00</th>\n",
       "      <td>-0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-28 13:00:00</th>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-28 14:00:00</th>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-28 17:00:00</th>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01 10:00:00</th>\n",
       "      <td>-0.023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2089 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        UJ\n",
       "time                      \n",
       "2021-12-27 09:00:00  0.162\n",
       "2021-12-27 10:00:00  0.040\n",
       "2021-12-28 17:00:00 -0.006\n",
       "2021-12-29 03:00:00  0.016\n",
       "2021-12-29 13:00:00  0.064\n",
       "...                    ...\n",
       "2023-07-28 12:00:00 -0.035\n",
       "2023-07-28 13:00:00  0.022\n",
       "2023-07-28 14:00:00  0.673\n",
       "2023-07-28 17:00:00  0.396\n",
       "2023-08-01 10:00:00 -0.023\n",
       "\n",
       "[2089 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift the index in df2 back by one hour\n",
    "UJ_returns.index = UJ_returns.index - pd.Timedelta(hours=1)\n",
    "\n",
    "# Keep only the rows in UJ_returns that match the index in df1\n",
    "UJ_returns = UJ_returns[UJ_returns.index.isin(EU_GU.index)]\n",
    "UJ_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "eb31ab93-b5ba-4993-8954-364f32b6bddb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Correlation at 1\n",
      "No Correlation at 1\n",
      "No Correlation at 1\n",
      "No Correlation at 2\n",
      "No Correlation at 2\n",
      "No Correlation at 2\n",
      "No Correlation at 3\n",
      "No Correlation at 3\n",
      "No Correlation at 3\n",
      "No Correlation at 4\n",
      "No Correlation at 4\n",
      "No Correlation at 4\n",
      "No Correlation at 5\n",
      "No Correlation at 5\n",
      "No Correlation at 5\n",
      "No Correlation at 6\n",
      "No Correlation at 6\n",
      "No Correlation at 6\n",
      "No Correlation at 7\n",
      "No Correlation at 7\n",
      "No Correlation at 7\n",
      "No Correlation at 8\n",
      "No Correlation at 8\n",
      "No Correlation at 8\n",
      "No Correlation at 9\n",
      "No Correlation at 9\n",
      "No Correlation at 9\n",
      "No Correlation at 10\n",
      "No Correlation at 10\n",
      "No Correlation at 10\n",
      "No Correlation at 11\n",
      "No Correlation at 11\n",
      "No Correlation at 11\n",
      "No Correlation at 12\n",
      "No Correlation at 12\n",
      "No Correlation at 12\n",
      "No Correlation at 13\n",
      "No Correlation at 13\n",
      "No Correlation at 13\n",
      "No Correlation at 14\n",
      "No Correlation at 14\n",
      "No Correlation at 14\n",
      "No Correlation at 15\n",
      "No Correlation at 15\n",
      "No Correlation at 15\n",
      "No Correlation at 16\n",
      "No Correlation at 16\n",
      "No Correlation at 16\n",
      "No Correlation at 17\n",
      "No Correlation at 17\n",
      "No Correlation at 17\n",
      "No Correlation at 18\n",
      "No Correlation at 18\n",
      "No Correlation at 18\n",
      "No Correlation at 19\n",
      "No Correlation at 19\n",
      "No Correlation at 19\n",
      "No Correlation at 20\n",
      "No Correlation at 20\n",
      "No Correlation at 20\n",
      "No Correlation at 21\n",
      "No Correlation at 21\n",
      "No Correlation at 21\n",
      "No Correlation at 22\n",
      "No Correlation at 22\n",
      "No Correlation at 22\n",
      "No Correlation at 23\n",
      "No Correlation at 23\n",
      "No Correlation at 23\n"
     ]
    }
   ],
   "source": [
    "def corr_measure(pearson_corr, i):\n",
    "    if pearson_corr > abs(0.5):\n",
    "        print(f'Lag {i} shows a moderate correlation')\n",
    "    else:\n",
    "        print(f'No Correlation at {i}')\n",
    "\n",
    "for i in range(1, 24):\n",
    "    # Make a copy of the original dataframe\n",
    "    UJ_returns_copy = UJ_returns.copy()\n",
    "\n",
    "    # Shift the index in the copy back by one hour\n",
    "    UJ_returns_copy.index = UJ_returns_copy.index - pd.Timedelta(hours=i)\n",
    "\n",
    "    # Keep only the rows in UJ_returns_copy that match the index in EU_GU\n",
    "    UJ_returns_copy = UJ_returns_copy[UJ_returns_copy.index.isin(EU_GU.index)]\n",
    "    \n",
    "    min_length = min(len(EU_GU), len(UJ_returns_copy))\n",
    "\n",
    "    pearson_corr = np.corrcoef(EU_GU['EU'].tail(min_length), UJ_returns_copy['UJ'].tail(min_length))[0, 1]\n",
    "    corr_measure(pearson_corr, i)\n",
    "    # print(f'Lag {i} - {pearson_corr} for EU')\n",
    "    \n",
    "    pearson_corr = np.corrcoef(UJ_returns_copy['UJ'].tail(min_length), EU_GU['GU'].tail(min_length))[0, 1]\n",
    "    corr_measure(pearson_corr, i)\n",
    "    # print(f'Lag {i} - {pearson_corr} for GU')\n",
    "    \n",
    "    pearson_corr = np.corrcoef(EU_GU['EU'].tail(min_length), UJ_returns_copy['UJ'].tail(min_length))[0, 1]\n",
    "    corr_measure(pearson_corr, i)\n",
    "    # print(f'Lag {i} - {pearson_corr} for the spread')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7376b272-13ef-4e8c-981a-23a9a78b5b2e",
   "metadata": {},
   "source": [
    "# Interlagged Strategy\n",
    "## Hypothesis\n",
    "\n",
    "For each base currencies respective forex opening (Sydney for AUD, Tokyo for JPY etc etc), there will be a correlation of returns at a later time period within the same currency at a consistent hour, whether it seem like an arbitrary number or it be at the next session. For example, if AUDUSD returns +10 pips in the Syd open, later whether it be Tokyo, London or New York or a seemingly arbitrary period, it will return 10 or more pips within an hour. \n",
    "\n",
    "## Method\n",
    "\n",
    "Gather data for AUDUSD, USDJPY, GBPUSD and EURUSD. Within each dataframe, run a correlation analysis between the opening time (Start at the hourly and go down to the minute timeframe). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be338a05-0f04-49d6-a057-47b13ec23bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To edit\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def sing_corr(symbol, base_hour, timeframe, bars = 100):\n",
    "\n",
    "    correlations = {}  # Store correlations here, keyed by time string\n",
    "\n",
    "    # Convert timeframe string to corresponding MetaTrader 5 constant\n",
    "    timeframe_dict = {'M1': mt5.TIMEFRAME_M1, 'M2': mt5.TIMEFRAME_M2, 'M3': mt5.TIMEFRAME_M3, 'M5': mt5.TIMEFRAME_M5, \n",
    "                      'M10': mt5.TIMEFRAME_M10, 'M15': mt5.TIMEFRAME_M15, 'M30': mt5.TIMEFRAME_M30, 'H1': mt5.TIMEFRAME_H1, \n",
    "                      'H2': mt5.TIMEFRAME_H2, 'H3': mt5.TIMEFRAME_H3, 'H4': mt5.TIMEFRAME_H4, 'H6': mt5.TIMEFRAME_H6, \n",
    "                      'H8': mt5.TIMEFRAME_H8, 'H12': mt5.TIMEFRAME_H12, 'D1': mt5.TIMEFRAME_D1, 'W1': mt5.TIMEFRAME_W1, \n",
    "                      'MN1': mt5.TIMEFRAME_MN1}\n",
    "    mt5_timeframe = timeframe_dict[timeframe]\n",
    "\n",
    "    # Calculate the duration of the time period in hours\n",
    "    if timeframe[-1] == 'M':\n",
    "        duration = timedelta(minutes=int(timeframe[:-1]))\n",
    "    elif timeframe[-1] == 'H':\n",
    "        duration = timedelta(hours=int(timeframe[:-1]))\n",
    "    elif timeframe[-1] == 'D':\n",
    "        duration = timedelta(days=int(timeframe[:-1]))\n",
    "    elif timeframe[-1] == 'W':\n",
    "        duration = timedelta(weeks=int(timeframe[:-1]))\n",
    "    else: # 'MN1'\n",
    "        duration = timedelta(days=int(timeframe[:-1]) * 30) # Roughly convert months to days\n",
    "\n",
    "    # Get data for base_hour\n",
    "    base_ts1 = datetime.strptime(f'{base_hour}:00', '%H:%M').time()\n",
    "    base_ts2 = (datetime.combine(datetime.today(), base_ts1) + duration).time()\n",
    "    base_ts1, base_ts2 = [t.strftime('%H:%M') for t in [base_ts1, base_ts2]]\n",
    "\n",
    "    base_prices = get_rates(symbol, mt5_timeframe, 50000)\n",
    "    base_prices = base_prices.between_time(base_ts1, base_ts2)\n",
    "    base_prices['returns'] = base_prices['close'] - base_prices['open']\n",
    "\n",
    "    for h in range(24):  # For each hour of the day\n",
    "        if h == base_hour:  # Skip the base_hour\n",
    "            continue\n",
    "\n",
    "        ts1 = datetime.strptime(f'{h}:00', '%H:%M').time()\n",
    "        ts2 = (datetime.combine(datetime.today(), ts1) + duration).time()\n",
    "        ts1, ts2 = [t.strftime('%H:%M') for t in [ts1, ts2]]\n",
    "\n",
    "        prices = get_rates(symbol, mt5_timeframe, 50000)\n",
    "        prices = prices.between_time(ts1, ts2)\n",
    "        prices['returns'] = prices['close'] - prices['open']\n",
    "\n",
    "        pearson_corr = np.corrcoef(base_prices['returns'].tail(bars), prices['returns'].tail(bars))[0, 1]  # Store correlation\n",
    "\n",
    "        if abs(pearson_corr) > 0.15:\n",
    "            correlations[f'{base_ts1}-{ts1}'] = pearson_corr\n",
    "\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c33e73af-2ff1-47d9-aff8-a3db718a616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "def t3_sing_corr(symbol, base_hour, bars = 100):\n",
    "\n",
    "    correlations = {}  # Store correlations here, keyed by time string\n",
    "    \n",
    "    ordered_correlations = {}\n",
    "\n",
    "    # Get data for base_hour\n",
    "    base_ts1 = datetime.strptime(f'{base_hour}:00', '%H:%M').time()\n",
    "    base_ts2 = (datetime.combine(datetime.today(), base_ts1) + timedelta(hours=1)).time()\n",
    "    base_ts1, base_ts2 = [t.strftime('%H:%M') for t in [base_ts1, base_ts2]]\n",
    "\n",
    "    base_prices = get_rates(symbol, mt5.TIMEFRAME_H1, 50000)\n",
    "    base_prices = base_prices.between_time(base_ts1, base_ts2)\n",
    "    base_prices['returns'] = base_prices['close'] - base_prices['open']\n",
    "\n",
    "    for h in range(24):  # For each hour of the day\n",
    "        if h == base_hour:  # Skip the base_hour\n",
    "            continue\n",
    "\n",
    "        ts1 = datetime.strptime(f'{h}:00', '%H:%M').time()\n",
    "        ts2 = (datetime.combine(datetime.today(), ts1) + timedelta(hours=1)).time()\n",
    "        ts1, ts2 = [t.strftime('%H:%M') for t in [ts1, ts2]]\n",
    "\n",
    "        prices = get_rates(symbol, mt5.TIMEFRAME_H1, 50000)\n",
    "        prices = prices.between_time(ts1, ts2)\n",
    "        prices['returns'] = prices['close'] - prices['open']\n",
    "\n",
    "        pearson_corr = np.corrcoef(base_prices['returns'].tail(bars), prices['returns'].tail(bars))[0, 1]  # Store correlation\n",
    "\n",
    "        if abs(pearson_corr) > 0.2:\n",
    "            correlations[f'{base_ts1}-{ts1}'] = pearson_corr\n",
    "        \n",
    "        if abs(pearson_corr) > 0.4:\n",
    "            ordered_correlations[f'{base_ts1}-{ts1} | 0.4 and over'] = pearson_corr\n",
    "        elif abs(pearson_corr) > 0.3:\n",
    "            ordered_correlations[f'{base_ts1}-{ts1} | 0.3 to 0.4'] = pearson_corr\n",
    "        elif abs(pearson_corr) > 0.2:\n",
    "            ordered_correlations[f'{base_ts1}-{ts1} | 0.2 to 0.3'] = pearson_corr\n",
    "\n",
    "    return correlations, ordered_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4716f4ce-755b-41e3-ab16-f129c60a4a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assume mini_list and get_rates are defined elsewhere.\n",
    "mini_list = ['AUDUSD.a', 'CADJPY.a', 'EURCAD.a', 'EURGBP.a']\n",
    "\n",
    "def t3_sing_corr(symbol, base_hour, bars=100):\n",
    "    base_ts1 = datetime.strptime(f'{base_hour}:00', '%H:%M').time()\n",
    "    base_ts2 = (datetime.combine(datetime.today(), base_ts1) + timedelta(hours=1)).time()\n",
    "    base_ts1, base_ts2 = [t.strftime('%H:%M') for t in [base_ts1, base_ts2]]\n",
    "\n",
    "    base_prices = get_rates(symbol, mt5.TIMEFRAME_H1, 50000)\n",
    "    base_prices = base_prices.between_time(base_ts1, base_ts2)\n",
    "    base_prices['returns'] = base_prices['close'] - base_prices['open']\n",
    "\n",
    "    correlations = {}\n",
    "    ordered_correlations = defaultdict(list)\n",
    "\n",
    "    for h in range(24):\n",
    "        if h == base_hour:\n",
    "            continue\n",
    "\n",
    "        ts1 = datetime.strptime(f'{h}:00', '%H:%M').time()\n",
    "        ts2 = (datetime.combine(datetime.today(), ts1) + timedelta(hours=1)).time()\n",
    "        ts1, ts2 = [t.strftime('%H:%M') for t in [ts1, ts2]]\n",
    "\n",
    "        prices = get_rates(symbol, mt5.TIMEFRAME_H1, 50000)\n",
    "        prices = prices.between_time(ts1, ts2)\n",
    "        prices['returns'] = prices['close'] - prices['open']\n",
    "\n",
    "        pearson_corr = np.corrcoef(base_prices['returns'].tail(bars), prices['returns'].tail(bars))[0, 1]\n",
    "\n",
    "        if abs(pearson_corr) > 0.2:\n",
    "            correlations[f'{base_ts1}-{ts1} | {symbol}'] = pearson_corr\n",
    "\n",
    "        if abs(pearson_corr) > 0.4:\n",
    "            ordered_correlations['0.4 and over'].append((f'{base_ts1}-{ts1}', pearson_corr, symbol))\n",
    "        elif abs(pearson_corr) > 0.3:\n",
    "            ordered_correlations['0.3 to 0.4'].append((f'{base_ts1}-{ts1}', pearson_corr, symbol))\n",
    "        elif abs(pearson_corr) > 0.2:\n",
    "            ordered_correlations['0.2 to 0.3'].append((f'{base_ts1}-{ts1}', pearson_corr, symbol))\n",
    "\n",
    "    return correlations, ordered_correlations\n",
    "\n",
    "correlations_all = {}\n",
    "ordered_correlations_all = defaultdict(list)\n",
    "\n",
    "for symbol in mini_list:\n",
    "    for i in range(24):\n",
    "        correlations, ordered_correlations = t3_sing_corr(symbol, i, bars=100)\n",
    "        correlations_all.update(correlations)\n",
    "        for key in ordered_correlations.keys():\n",
    "            ordered_correlations_all[key].extend(ordered_correlations[key])\n",
    "#     print(f\"{symbol} Analysed\")\n",
    "\n",
    "# print(f'All Correlations:\\n{correlations_all}')\n",
    "# print(f'Ordered Correlations:\\n{dict(ordered_correlations_all)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31e1560a-77f2-44ad-bb84-64f135075748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = ordered_correlations_all\n",
    "ordered_correlations_all = defaultdict(list)\n",
    "for key in data.keys():\n",
    "    ordered_correlations_all[key] = [item for item in data[key] if int(item[0].split('-')[0].split(':')[0]) < int(item[0].split('-')[1].split(':')[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8f7e1-6a0d-4c07-b57f-f9accb619303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46b298de-a581-452d-a702-2b72944c1e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('11:00-12:00', 0.5126344108642167, 'AUDUSD.a'),\n",
       " ('12:00-13:00', 0.5032255028208726, 'AUDUSD.a'),\n",
       " ('00:00-23:00', 0.5011093963323368, 'CADJPY.a'),\n",
       " ('02:00-19:00', -0.41536472525737894, 'CADJPY.a'),\n",
       " ('06:00-19:00', 0.5593982056420923, 'CADJPY.a'),\n",
       " ('07:00-20:00', 0.4819061913941256, 'CADJPY.a'),\n",
       " ('07:00-22:00', 0.41878573443095174, 'CADJPY.a'),\n",
       " ('12:00-13:00', 0.5512744106155025, 'CADJPY.a'),\n",
       " ('20:00-23:00', -0.4978029044896767, 'CADJPY.a'),\n",
       " ('00:00-23:00', 0.5122286567361735, 'EURCAD.a'),\n",
       " ('12:00-13:00', 0.5315385861581632, 'EURCAD.a'),\n",
       " ('11:00-12:00', 0.4634040683159789, 'EURGBP.a'),\n",
       " ('12:00-13:00', 0.4118188699495316, 'EURGBP.a')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_correlations = ordered_correlations_all['0.4 and over']\n",
    "correct_data = [item for item in strong_correlations if int(item[0].split('-')[0].split(':')[0]) < int(item[0].split('-')[1].split(':')[0])]\n",
    "correct_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2bc026d-00e1-4f6a-adfd-58569584dc7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Results are promising, will copy code to a trading script for further analysis / testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "daa1fe14-5fd7-4b3b-a75f-cded42044731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUDUSD.a',\n",
       " 'NZDUSD.a',\n",
       " 'GBPUSD.a',\n",
       " 'EURUSD.a',\n",
       " 'USDCAD.a',\n",
       " 'GBPAUD.a',\n",
       " 'GBPNZD.a',\n",
       " 'GBPCAD.a',\n",
       " 'AUDJPY.a',\n",
       " 'USDJPY.a',\n",
       " 'NZDJPY.a',\n",
       " 'GBPJPY.a',\n",
       " 'EURJPY.a',\n",
       " 'CADJPY.a',\n",
       " 'EURAUD.a',\n",
       " 'EURNZD.a',\n",
       " 'EURGBP.a',\n",
       " 'EURJPY.a',\n",
       " 'EURCAD.a']"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USD_SYMBOLS = ['AUDUSD.a', 'NZDUSD.a', 'GBPUSD.a', 'EURUSD.a', 'USDCAD.a']\n",
    "GBP_SYMBOLS = ['GBPAUD.a', 'GBPNZD.a', 'GBPCAD.a']\n",
    "JPY_SYMBOLS = ['AUDJPY.a', 'USDJPY.a', 'NZDJPY.a', 'GBPJPY.a', 'EURJPY.a', 'CADJPY.a']\n",
    "EUR_SYMBOLS = ['EURAUD.a', 'EURNZD.a', 'EURGBP.a', 'EURJPY.a', 'EURCAD.a']\n",
    "\n",
    "combined_lst = USD_SYMBOLS + GBP_SYMBOLS + JPY_SYMBOLS + EUR_SYMBOLS\n",
    "combined_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e63d7f3-d97a-4125-a86b-b18a6887cbaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hypothesis \n",
    "Currency prices whose sessions open prior to other sessions can be a leading indicator of prices for currencies sessions not yet opened, which can be found through interdependent and time lagged analysis. For example, if AUDUSD returns positive in the first hour of the Syd open, USDJPY is expected to return positive too. \n",
    "\n",
    "## Method\n",
    "\n",
    "Gather data on the first 5min to 60min bars of each open, starting with Sydney. Will base currencies against the USD Markets open in the following order:\n",
    "GMT Time (MT5 is GMT +3)\n",
    "- Sydney: 9PM / 21:00 (AUDUSD)\n",
    "- Tokyo: 12AM / 00:00 (USDJPY)\n",
    "- London: 7AM / 7:00(GBPUSD)\n",
    "- New York: 1PM / 13:00 (EURUSD)\n",
    "\n",
    "Run a Pearson Correlation and a Granger Causality method on the gathered data and the respective currencies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4c59e43c-3770-4023-aff5-be6e373f14b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def corr_tool(symbol1, symbol2, timeframe, bars):\n",
    "    print(f'Starting Pearson Correlation Analysis for {symbol1}, {symbol2} at {timeframe} for {bars} bars.')\n",
    "\n",
    "    pair1 = get_rates(symbol1, timeframe, bars)\n",
    "    pair2 = get_rates(symbol2,  timeframe, bars)\n",
    "    \n",
    "    s1 = input('Start Time for X?')\n",
    "    s2 = input('End time for X?')\n",
    "\n",
    "    e1 = input('Start time for Y?')\n",
    "    e2 = input('End time for Y?')\n",
    "\n",
    "    print('Times to investigate are:'\n",
    "          f'\\n{s1} to {s2} and {e1} to {e2}')\n",
    "    \n",
    "    pair1_returns = pair1['open'] - pair1['close']\n",
    "    pair2_returns = pair2['open'] - pair2['close']\n",
    "\n",
    "    lst = []\n",
    "\n",
    "    un_corr = []\n",
    "\n",
    "    for i in range(50):\n",
    "        pearson_corr = np.corrcoef(syd_opens['Syd Pip Return'].tail(i), tokyo_opens['Tko Pip Return'].tail(i))\n",
    "        if pearson_corr[0][1] > 0.5:\n",
    "            # print(f'Pearson correlation {pearson_corr[0][1]} on lag {i}')\n",
    "            lst.append(i)\n",
    "        else:\n",
    "            un_corr.append(i)\n",
    "            \n",
    "    print(f'Lags that have a correlation higher than 0.5 are:'\n",
    "        f'\\n{lst}')\n",
    "    print(f'Total Lags: {len(lst)}')\n",
    "\n",
    "    import datetime\n",
    "\n",
    "    day_counts = {}\n",
    "\n",
    "    for i in lst:\n",
    "        date = syd_opens.index[i]\n",
    "        day_name = date.day_name()\n",
    "\n",
    "        if day_name not in day_counts:\n",
    "            day_counts[day_name] = 0\n",
    "\n",
    "        day_counts[day_name] += 1\n",
    "    print(f'Days that have correlations between AUDUSD and USDJPY of more than 0.5 are:')\n",
    "\n",
    "    for day, count in day_counts.items():\n",
    "        print(f'{day}: {count}')\n",
    "        \n",
    "    day_counts = {}\n",
    "\n",
    "    for i in un_corr:\n",
    "        date = syd_opens.index[i]\n",
    "        day_name = date.day_name()\n",
    "\n",
    "        if day_name not in day_counts:\n",
    "            day_counts[day_name] = 0\n",
    "\n",
    "        day_counts[day_name] += 1\n",
    "    print(f'Days that do not have correlations between AUDUSD and USDJPY of more than 0.5 are:')\n",
    "\n",
    "    for day, count in day_counts.items():\n",
    "        print(f'{day}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78722e7d-3e80-48c9-90ed-c42c68674d14",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pearson Correlation Analysis for AUDUSD.a, AUDJPY.a at 16385 for 50000 bars.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Start Time for AUDUSD.a? 19:00\n",
      "End time for AUDUSD.a? 19:59\n",
      "Start time for AUDJPY.a? 20:00\n",
      "End time for AUDJPY.a 20:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times to investigate are:\n",
      "19:00 to 19:59 and 20:00 to 20:59\n",
      "Lags that have a correlation higher than 0.5 are:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "Total Lags: 50\n",
      "Days that have correlations between AUDUSD.a and AUDJPY.aof more than 0.5 are:\n",
      "Monday: 10\n",
      "Tuesday: 10\n",
      "Wednesday: 10\n",
      "Thursday: 10\n",
      "Friday: 10\n",
      "Days that do not have correlations between AUDUSD.a and AUDJPY.a of more than 0.5 are:\n"
     ]
    }
   ],
   "source": [
    "corr_tool('AUDUSD.a', 'AUDJPY.a', mt5.TIMEFRAME_H1, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "48f8e48a-17dd-432d-ac69-dadfbe20019c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.50440698],\n",
       "       [0.50440698, 1.        ]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Starting with AUDUSD, Hourly Timeframe \n",
    "AUDUSD = get_rates('AUDUSD.a', mt5.TIMEFRAME_H1, 50000)\n",
    "syd_opens = AUDUSD.between_time('19:00','19:59')\n",
    "syd_opens['returns'] = syd_opens['close'] - syd_opens['open']\n",
    "USDJPY = get_rates('USDJPY.a', mt5.TIMEFRAME_H1, 50000)\n",
    "tokyo_opens = USDJPY.between_time('20:00', '20:59')\n",
    "tokyo_opens['returns'] = tokyo_opens['close'] - tokyo_opens['open']\n",
    "tail = 50 \n",
    "pearson_corr = np.corrcoef(syd_opens['returns'].tail(tail), tokyo_opens['returns'].tail(tail)) \n",
    "pearson_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "98d04fa7-3e60-4c26-b623-ddbf204f452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_mini_corr(s1, s2, bars = 10000):\n",
    "    \n",
    "    \n",
    "    ts1_1 = input(f'Start Time for {s1}?')\n",
    "    ts1_2 = input(f'End time for {s1}?')\n",
    "\n",
    "    ts2_1 = input(f'Start time for {s2}?')\n",
    "    ts2_2 = input(f'End time for {s2}?')\n",
    "    \n",
    "    p1 = get_rates(s1, mt5.TIMEFRAME_H1, 50000)\n",
    "    p1 = p1.between_time(ts1_1, ts1_2)\n",
    "    p1['returns'] = p1['close'] - p1['open']\n",
    "    p2 = get_rates(s2, mt5.TIMEFRAME_H1, 50000)\n",
    "    p2 = p2.between_time(ts2_1, ts2_2)\n",
    "    p2['returns'] = p2['close'] - p2['open']\n",
    "    \n",
    "    pearson_corr = np.corrcoef(p1['returns'].tail(tail), p2['returns'].tail(tail)) \n",
    "    return pearson_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "67481bde-d6ac-4c94-bf34-de1d3e0d758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Start Time for AUDUSD.a? 10:00\n",
      "End time for AUDUSD.a? 10:59\n",
      "Start time for USDJPY.a? 13:00\n",
      "End time for USDJPY.a? 13:59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.07723649],\n",
       "       [0.07723649, 1.        ]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_mini_corr('AUDUSD.a', 'USDJPY.a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565c3b5-8129-4d87-b3b6-8fb804bba7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def hour_mini_corr(s1, s2, bars = 100):\n",
    "\n",
    "    correlations = {}  # Store correlations here, keyed by time string\n",
    "\n",
    "    for h in range(24):  # For each hour of the day\n",
    "        ts1_1 = datetime.strptime(f'{h}:00', '%H:%M').time()\n",
    "        ts1_2 = (datetime.combine(datetime.today(), ts1_1) + timedelta(hours=1)).time()\n",
    "\n",
    "        ts2_1 = (datetime.combine(datetime.today(), ts1_1) + timedelta(hours=1)).time()\n",
    "        ts2_2 = (datetime.combine(datetime.today(), ts2_1) + timedelta(hours=1)).time()\n",
    "\n",
    "        # Convert to strings for use in function\n",
    "        ts1_1, ts1_2, ts2_1, ts2_2 = [t.strftime('%H:%M') for t in [ts1_1, ts1_2, ts2_1, ts2_2]]\n",
    "\n",
    "        p1 = get_rates(s1, mt5.TIMEFRAME_H1, 50000)\n",
    "        p1 = p1.between_time(ts1_1, ts1_2)\n",
    "        p1['returns'] = p1['close'] - p1['open']\n",
    "        p2 = get_rates(s2, mt5.TIMEFRAME_H1, 50000)\n",
    "        p2 = p2.between_time(ts2_1, ts2_2)\n",
    "        p2['returns'] = p2['close'] - p2['open']\n",
    "\n",
    "        pearson_corr = np.corrcoef(p1['returns'].tail(bars), p2['returns'].tail(bars)) \n",
    "        correlations[f'{ts1_1}-{ts2_1}'] = pearson_corr[0, 1]  # Store correlation\n",
    "\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d58590-d4d0-431c-b2f4-fe844487c215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1cc76eec-4607-44f4-9575-e1073f725eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def mini_corr(s1, s2, bars = 500):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for offset in range(24):\n",
    "        for h in range(24):\n",
    "            \n",
    "            # start and end times for first time series\n",
    "            ts1_1 = timedelta(hours=h).seconds // 3600\n",
    "            ts1_2 = (ts1_1 + 1) % 24\n",
    "            \n",
    "            # offset hours for second time series\n",
    "            ts2_1 = (ts1_1 + 1 + offset) % 24\n",
    "            ts2_2 = (ts2_1 + 1) % 24\n",
    "            \n",
    "            p1 = get_rates(s1, mt5.TIMEFRAME_H1, 50000)\n",
    "            p1 = p1.between_time(f'{ts1_1:02d}:00', f'{ts1_2:02d}:00')\n",
    "            p1['returns'] = p1['close'] - p1['open']\n",
    "\n",
    "            p2 = get_rates(s2, mt5.TIMEFRAME_H1, 50000)\n",
    "            p2 = p2.between_time(f'{ts2_1:02d}:00', f'{ts2_2:02d}:00')\n",
    "            p2['returns'] = p2['close'] - p2['open']\n",
    "\n",
    "            if len(p1['returns']) > 0 and len(p2['returns']) > 0:\n",
    "                pearson_corr = np.corrcoef(p1['returns'].tail(bars), p2['returns'].tail(bars))[0, 1]\n",
    "\n",
    "                if abs(pearson_corr) > 0.5:\n",
    "                    results.append((ts1_1, ts1_2, ts2_1, ts2_2, pearson_corr))\n",
    "                    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a2f16a4f-79be-48f3-b2c4-04caaa8e3778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13, 14, 13, 14, -0.5069723012444712),\n",
       " (14, 15, 14, 15, -0.7897661689149376),\n",
       " (15, 16, 15, 16, -0.7678376747086922),\n",
       " (16, 17, 16, 17, -0.582745257763089),\n",
       " (17, 18, 17, 18, -0.5154347958641352),\n",
       " (19, 20, 19, 20, -0.556167066543711),\n",
       " (20, 21, 20, 21, -0.612978471752775),\n",
       " (21, 22, 21, 22, -0.5632127428717656)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_corr('AUDUSD.a', 'USDJPY.a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "525a6ec6-d45d-4601-8e0e-3d68d446a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v3_mini_corr(s1, s2, bars=100):\n",
    "    for offset in range(24):\n",
    "        for hour in range(24):\n",
    "            ts1_1 = hour\n",
    "            ts1_2 = (ts1_1 + 1) % 24\n",
    "            \n",
    "            ts2_1 = (hour + 1 + offset) % 24\n",
    "            ts2_2 = (ts2_1 + 1) % 24\n",
    "            \n",
    "            # Convert to string format for the 'between_time' function\n",
    "            ts1_1, ts1_2, ts2_1, ts2_2 = [f'{t:02d}:00' for t in [ts1_1, ts1_2, ts2_1, ts2_2]]\n",
    "            \n",
    "            p1 = get_rates(s1, mt5.TIMEFRAME_H1, 50000)\n",
    "            p1 = p1.between_time(ts1_1, ts1_2)\n",
    "            p1['returns'] = p1['close'] - p1['open']\n",
    "            \n",
    "            p2 = get_rates(s2, mt5.TIMEFRAME_H1, 50000)\n",
    "            p2 = p2.between_time(ts2_1, ts2_2)\n",
    "            p2['returns'] = p2['close'] - p2['open']\n",
    "            \n",
    "            if len(p1['returns']) < bars or len(p2['returns']) < bars:\n",
    "                print(f'Insufficient data for {s1} between {ts1_1} and {ts1_2} or {s2} between {ts2_1} and {ts2_2}')\n",
    "                continue\n",
    "            \n",
    "            pearson_corr = np.corrcoef(p1['returns'].tail(bars), p2['returns'].tail(bars))[0, 1]\n",
    "            \n",
    "            if abs(pearson_corr) > 0.5:\n",
    "                print(f'Found correlation {pearson_corr} for {s1} between {ts1_1} and {ts1_2} and {s2} between {ts2_1} and {ts2_2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6d108713-eb0c-4df5-9011-234f986cf76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found correlation -0.7307982835086003 for AUDUSD.a between 14:00 and 15:00 and USDJPY.a between 14:00 and 15:00\n",
      "Found correlation -0.7374479429221158 for AUDUSD.a between 15:00 and 16:00 and USDJPY.a between 15:00 and 16:00\n",
      "Found correlation -0.5174647667371404 for AUDUSD.a between 16:00 and 17:00 and USDJPY.a between 16:00 and 17:00\n"
     ]
    }
   ],
   "source": [
    "v3_mini_corr('AUDUSD.a', 'USDJPY.a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a56a1042-8e99-454a-a2f0-50edf7efdb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lags that have a correlation higher than 0.5 are:\n",
      "[6, 7, 9, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 33, 34, 35, 36, 39, 49]\n",
      "Total Lags: 20\n"
     ]
    }
   ],
   "source": [
    "#Correlation for AUDJPY Syd Open - USDJPY Tokyo Open\n",
    "lst = []\n",
    "\n",
    "un_corr = []\n",
    "\n",
    "for i in range(50):\n",
    "    pearson_corr = np.corrcoef(syd_opens['Syd Pip Return'].tail(i), tokyo_opens['Tko Pip Return'].tail(i))\n",
    "    if pearson_corr[0][1] > 0.5:\n",
    "        # print(f'Pearson correlation {pearson_corr[0][1]} on lag {i}')\n",
    "        lst.append(i)\n",
    "    else:\n",
    "        un_corr.append(i)\n",
    "        \n",
    "print(f'Lags that have a correlation higher than 0.5 are:'\n",
    "      f'\\n{lst}')\n",
    "print(f'Total Lags: {len(lst)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4cd56253-bbcd-49f0-92d4-cf31122b2bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days that have correlations between AUDUSD and USDJPY of more than 0.5 are:\n",
      "Tuesday: 4\n",
      "Wednesday: 3\n",
      "Friday: 6\n",
      "Monday: 5\n",
      "Thursday: 2\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "day_counts = {}\n",
    "\n",
    "for i in lst:\n",
    "    date = syd_opens.index[i]\n",
    "    day_name = date.day_name()\n",
    "\n",
    "    if day_name not in day_counts:\n",
    "        day_counts[day_name] = 0\n",
    "\n",
    "    day_counts[day_name] += 1\n",
    "print(f'Days that have correlations between AUDUSD and USDJPY of more than 0.5 are:')\n",
    "\n",
    "for day, count in day_counts.items():\n",
    "    print(f'{day}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f97e9f83-5b2a-4253-8bc9-21f841a769c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days that do not have correlations between AUDUSD and USDJPY of more than 0.5 are:\n",
      "Monday: 5\n",
      "Tuesday: 6\n",
      "Wednesday: 7\n",
      "Thursday: 8\n",
      "Friday: 4\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "day_counts = {}\n",
    "\n",
    "for i in un_corr:\n",
    "    date = syd_opens.index[i]\n",
    "    day_name = date.day_name()\n",
    "\n",
    "    if day_name not in day_counts:\n",
    "        day_counts[day_name] = 0\n",
    "\n",
    "    day_counts[day_name] += 1\n",
    "print(f'Days that do not have correlations between AUDUSD and USDJPY of more than 0.5 are:')\n",
    "\n",
    "for day, count in day_counts.items():\n",
    "    print(f'{day}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55160da7-5dbc-4204-a3d2-7ff88f27d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_tool(symbol1, symbol2, timeframe, bars):\n",
    "    print(f'Starting Pearson Correlation Analysis for {symbol1}, {symbol2} at {timeframe} for {bars} bars.')\n",
    "\n",
    "    s1 = input(f'Start Time for {symbol1}?')\n",
    "    s2 = input(f'End time for {symbol1}?')\n",
    "\n",
    "    e1 = input(f'Start time for {symbol2}?')\n",
    "    e2 = input(f'End time for {symbol2}')\n",
    "\n",
    "    pair1 = get_rates(symbol1, timeframe, bars)\n",
    "    explored_seg1 = pair1.between_time(s1, s2)\n",
    "    pair2 = get_rates(symbol2,  timeframe, bars)\n",
    "    explored_seg2 = pair2.between_time(e1, e2)\n",
    "    \n",
    "    print('Times to investigate are:'\n",
    "          f'\\n{s1} to {s2} and {e1} to {e2}')\n",
    "    \n",
    "    pair1_returns = pair1['open'] - pair1['close']\n",
    "    pair2_returns = pair2['open'] - pair2['close']\n",
    "\n",
    "    lst = []\n",
    "\n",
    "    un_corr = []\n",
    "\n",
    "    for i in range(50):\n",
    "        pearson_corr = np.corrcoef(pair1_returns.tail(50), pair2_returns.tail(50))\n",
    "        if pearson_corr[0][1] > 0.5:\n",
    "            # print(f'Pearson correlation {pearson_corr[0][1]} on lag {i}')\n",
    "            lst.append(i)\n",
    "        else:\n",
    "            un_corr.append(i)\n",
    "            \n",
    "    print(f'Lags that have a correlation higher than 0.5 are:'\n",
    "        f'\\n{lst}')\n",
    "    print(f'Total Lags: {len(lst)}')\n",
    "\n",
    "    import datetime\n",
    "\n",
    "    day_counts = {}\n",
    "\n",
    "    for i in lst:\n",
    "        date = syd_opens.index[i]\n",
    "        day_name = date.day_name()\n",
    "\n",
    "        if day_name not in day_counts:\n",
    "            day_counts[day_name] = 0\n",
    "\n",
    "        day_counts[day_name] += 1\n",
    "    print(f'Days that have correlations between {symbol1} and {symbol2}of more than 0.5 are:')\n",
    "\n",
    "    for day, count in day_counts.items():\n",
    "        print(f'{day}: {count}')\n",
    "        \n",
    "    day_counts = {}\n",
    "\n",
    "    for i in un_corr:\n",
    "        date = syd_opens.index[i]\n",
    "        day_name = date.day_name()\n",
    "\n",
    "        if day_name not in day_counts:\n",
    "            day_counts[day_name] = 0\n",
    "\n",
    "        day_counts[day_name] += 1\n",
    "    print(f'Days that do not have correlations between {symbol1} and {symbol2} of more than 0.5 are:')\n",
    "\n",
    "    for day, count in day_counts.items():\n",
    "        print(f'{day}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee2f2447-cb6e-4a6b-a5cf-8411c9ad877a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pearson Correlation Analysis for EURUSD.a, GBPUSD.a at 16385 for 50000 bars.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Start Time for EURUSD.a? 10:00\n",
      "End time for EURUSD.a? 10:59\n",
      "Start time for GBPUSD.a? 16:00\n",
      "End time for GBPUSD.a 16:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times to investigate are:\n",
      "10:00 to 10:59 and 16:00 to 16:59\n",
      "Lags that have a correlation higher than 0.5 are:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "Total Lags: 50\n",
      "Days that have correlations between EURUSD.a and GBPUSD.aof more than 0.5 are:\n",
      "Monday: 10\n",
      "Tuesday: 10\n",
      "Wednesday: 10\n",
      "Thursday: 10\n",
      "Friday: 10\n",
      "Days that do not have correlations between EURUSD.a and GBPUSD.a of more than 0.5 are:\n"
     ]
    }
   ],
   "source": [
    "corr_tool('EURUSD.a', 'GBPUSD.a', mt5.TIMEFRAME_H1, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a304af5-e108-48b7-8f05-e087a0dc554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair1 = get_rates('EURUSD.a', mt5.TIMEFRAME_H1, 10000)\n",
    "pair2 = get_rates('GBPUSD.a',  mt5.TIMEFRAME_H1, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f06e54-75ed-4647-b0ac-1301562cea14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30299294-8d8e-4afa-867c-9e4140bce261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
